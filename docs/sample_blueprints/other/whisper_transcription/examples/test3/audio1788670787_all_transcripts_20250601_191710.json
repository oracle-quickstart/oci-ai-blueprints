{
  "chunks": {
    "chunk_000.wav": {
      "chunk_id": "001",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: All right. Thank you all. Morning, afternoon. So my name is Amar Gowda. I am one of the\n[2025-06-01 19:13:30] Speaker 5: products.",
      "segments": [
        {
          "text": "All right. Thank you all. Morning, afternoon. So my name is Amar Gowda. I am one of the",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "products.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_001.wav": {
      "chunk_id": "002",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: managers leading the OCI Lens initiative. So right now it's kind of what we call incubation.",
      "segments": [
        {
          "text": "managers leading the OCI Lens initiative. So right now it's kind of what we call incubation.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_002.wav": {
      "chunk_id": "003",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: phases so we are not yet to be a mvp or closer to it so we're kind of getting early feedback",
      "segments": [
        {
          "text": "phases so we are not yet to be a mvp or closer to it so we're kind of getting early feedback",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_003.wav": {
      "chunk_id": "004",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: and this is like think of this as a kind of private preview in a way right so a little earlier on",
      "segments": [
        {
          "text": "and this is like think of this as a kind of private preview in a way right so a little earlier on",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_004.wav": {
      "chunk_id": "005",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: on the journey.\n[2025-06-01 19:13:26] Speaker 5: But this is something we started looking into,\n[2025-06-01 19:13:31] Speaker 5: which we, I think we spoke with.",
      "segments": [
        {
          "text": "on the journey.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "But this is something we started looking into,",
          "timestamp": "2025-06-01 19:13:26",
          "speaker": "Speaker 5"
        },
        {
          "text": "which we, I think we spoke with.",
          "timestamp": "2025-06-01 19:13:31",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_005.wav": {
      "chunk_id": "006",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: you, Cecil, you and the rest of the team on what does it take to operate at scale?",
      "segments": [
        {
          "text": "you, Cecil, you and the rest of the team on what does it take to operate at scale?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_006.wav": {
      "chunk_id": "007",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: what are the things that we could improve on, especially the monitoring, the health check.",
      "segments": [
        {
          "text": "what are the things that we could improve on, especially the monitoring, the health check.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_007.wav": {
      "chunk_id": "008",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: side of the things, which has, you know, you gave a set of requirements and that led us.",
      "segments": [
        {
          "text": "side of the things, which has, you know, you gave a set of requirements and that led us.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_008.wav": {
      "chunk_id": "009",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: to building something to help customers like you.\n[2025-06-01 19:13:30] Speaker 5: Okay, so I have a team here.\n[2025-06-01 19:13:32] Speaker 5: Joletta is...",
      "segments": [
        {
          "text": "to building something to help customers like you.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Okay, so I have a team here.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        },
        {
          "text": "Joletta is...",
          "timestamp": "2025-06-01 19:13:32",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_009.wav": {
      "chunk_id": "010",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: another software engineers somia on the call is our data scientist selection ml engineer\n[2025-06-01 19:13:30] Speaker 5: uh",
      "segments": [
        {
          "text": "another software engineers somia on the call is our data scientist selection ml engineer",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "uh",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_010.wav": {
      "chunk_id": "011",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: also have uh hithika who's our golang developer she's ex uh akis team so that's where if you all can",
      "segments": [
        {
          "text": "also have uh hithika who's our golang developer she's ex uh akis team so that's where if you all can",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_011.wav": {
      "chunk_id": "012",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: connect a little bit too.\n[2025-06-01 19:13:27] Speaker 5: All right. Today, I'm going to keep it more focused on the demo.",
      "segments": [
        {
          "text": "connect a little bit too.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "All right. Today, I'm going to keep it more focused on the demo.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_012.wav": {
      "chunk_id": "013",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: and what this tool is all about.\n[2025-06-01 19:13:27] Speaker 5: And then we'll, you know, answer questions\n[2025-06-01 19:13:29] Speaker 5: and kind of talk through.",
      "segments": [
        {
          "text": "and what this tool is all about.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "And then we'll, you know, answer questions",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        },
        {
          "text": "and kind of talk through.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_013.wav": {
      "chunk_id": "014",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: But most importantly, we want to hear if the current version has a set of features you're",
      "segments": [
        {
          "text": "But most importantly, we want to hear if the current version has a set of features you're",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_014.wav": {
      "chunk_id": "015",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: looking for? Is it missing? Is it you want to see something more? Because we are kind of very",
      "segments": [
        {
          "text": "looking for? Is it missing? Is it you want to see something more? Because we are kind of very",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_015.wav": {
      "chunk_id": "016",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: rapidly on a weekly sprint uh releasing the features to this and we are really happy to incorporate",
      "segments": [
        {
          "text": "rapidly on a weekly sprint uh releasing the features to this and we are really happy to incorporate",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_016.wav": {
      "chunk_id": "017",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: anything and work on how you can onboard to this by the way\n[2025-06-01 19:13:31] Speaker 5: uh so four areas where we are focused on",
      "segments": [
        {
          "text": "anything and work on how you can onboard to this by the way",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "uh so four areas where we are focused on",
          "timestamp": "2025-06-01 19:13:31",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_017.wav": {
      "chunk_id": "018",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: this solution is continuous GPU and cluster level monitoring of both NVIDIA GPUs and AMD GPUs.",
      "segments": [
        {
          "text": "this solution is continuous GPU and cluster level monitoring of both NVIDIA GPUs and AMD GPUs.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_018.wav": {
      "chunk_id": "019",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: together, right? So this is how we want to kind of platform\n[2025-06-01 19:13:29] Speaker 5: agnostic solution that works for all GPUs.",
      "segments": [
        {
          "text": "together, right? So this is how we want to kind of platform",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "agnostic solution that works for all GPUs.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_019.wav": {
      "chunk_id": "020",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: and has all the latest metrics available for you to digest and look at.\n[2025-06-01 19:13:32] Speaker 5: The next thing which we've highlighted...",
      "segments": [
        {
          "text": "and has all the latest metrics available for you to digest and look at.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "The next thing which we've highlighted...",
          "timestamp": "2025-06-01 19:13:32",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_020.wav": {
      "chunk_id": "021",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: focused on is the health checks piece to this right are my nodes healthy are they performing to\n[2025-06-01 19:13:30] Speaker 5: what they",
      "segments": [
        {
          "text": "focused on is the health checks piece to this right are my nodes healthy are they performing to",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "what they",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_021.wav": {
      "chunk_id": "022",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: should be uh active health checks active monitoring is is is a huge investment that we did uh and i'll\n[2025-06-01 19:13:32] Speaker 5: go over some",
      "segments": [
        {
          "text": "should be uh active health checks active monitoring is is is a huge investment that we did uh and i'll",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "go over some",
          "timestamp": "2025-06-01 19:13:32",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_022.wav": {
      "chunk_id": "023",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: details about what all health checks that we have enabled including the RDMA cluster level.",
      "segments": [
        {
          "text": "details about what all health checks that we have enabled including the RDMA cluster level.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_023.wav": {
      "chunk_id": "024",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: checks that we call MPI tests as part of the solution fully baked into.\n[2025-06-01 19:13:30] Speaker 5: We kept it to cloud native.",
      "segments": [
        {
          "text": "checks that we call MPI tests as part of the solution fully baked into.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "We kept it to cloud native.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_024.wav": {
      "chunk_id": "025",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: because I heard it very clear that it has to be Grafana, Prometheus, Native, or Otel, anything open source.",
      "segments": [
        {
          "text": "because I heard it very clear that it has to be Grafana, Prometheus, Native, or Otel, anything open source.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_025.wav": {
      "chunk_id": "026",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Cloud Native Alliance so that it's easy to be move between clouds or on-prem and use\n[2025-06-01 19:13:29] Speaker 5: the same existing.",
      "segments": [
        {
          "text": "Cloud Native Alliance so that it's easy to be move between clouds or on-prem and use",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "the same existing.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_026.wav": {
      "chunk_id": "027",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: tools you always used for for monitoring another area that we've paid attention and we built is the",
      "segments": [
        {
          "text": "tools you always used for for monitoring another area that we've paid attention and we built is the",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_027.wav": {
      "chunk_id": "028",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: team level tracking. A lot of these large size clusters are usually used by multiple teams and",
      "segments": [
        {
          "text": "team level tracking. A lot of these large size clusters are usually used by multiple teams and",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_028.wav": {
      "chunk_id": "029",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: everybody wants to know the health of their own subset of systems or how their experiment is\n[2025-06-01 19:13:30] Speaker 5: performing.",
      "segments": [
        {
          "text": "everybody wants to know the health of their own subset of systems or how their experiment is",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "performing.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_029.wav": {
      "chunk_id": "030",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: if they have an unhealthy node, all of those combinations.\n[2025-06-01 19:13:29] Speaker 5: And another important thing is about",
      "segments": [
        {
          "text": "if they have an unhealthy node, all of those combinations.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "And another important thing is about",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_030.wav": {
      "chunk_id": "031",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: cost tracking right people want to see how much computer resources they've used uh whatever the",
      "segments": [
        {
          "text": "cost tracking right people want to see how much computer resources they've used uh whatever the",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_031.wav": {
      "chunk_id": "032",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: the power the total gpu power they have used for running this experiment right those were a few\n[2025-06-01 19:13:29] Speaker 5: things that",
      "segments": [
        {
          "text": "the power the total gpu power they have used for running this experiment right those were a few",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "things that",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_032.wav": {
      "chunk_id": "033",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: that we also focused to build on this.\n[2025-06-01 19:13:29] Speaker 5: The current set of features that we have\n[2025-06-01 19:13:32] Speaker 5: and what we have built right now",
      "segments": [
        {
          "text": "that we also focused to build on this.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "The current set of features that we have",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        },
        {
          "text": "and what we have built right now",
          "timestamp": "2025-06-01 19:13:32",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_033.wav": {
      "chunk_id": "034",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: now is first thing tenancy level monitoring you no longer have region barriers right so we any",
      "segments": [
        {
          "text": "now is first thing tenancy level monitoring you no longer have region barriers right so we any",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_034.wav": {
      "chunk_id": "035",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: data, any region, OCI region you may be in, everything is monitorable as a single instance\n[2025-06-01 19:13:31] Speaker 5: for us.",
      "segments": [
        {
          "text": "data, any region, OCI region you may be in, everything is monitorable as a single instance",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "for us.",
          "timestamp": "2025-06-01 19:13:31",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_035.wav": {
      "chunk_id": "036",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: So I'm going to show you a demo.\n[2025-06-01 19:13:27] Speaker 5: We allow you to monitor either single, bare metal, virtual machine",
      "segments": [
        {
          "text": "So I'm going to show you a demo.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "We allow you to monitor either single, bare metal, virtual machine",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_036.wav": {
      "chunk_id": "037",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: instances or a full oke cluster or an hpc cluster that if you may be using slurm or a native uh",
      "segments": [
        {
          "text": "instances or a full oke cluster or an hpc cluster that if you may be using slurm or a native uh",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_037.wav": {
      "chunk_id": "038",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: called cluster network, compute cluster setup in OCI.\n[2025-06-01 19:13:29] Speaker 5: The third part of the feature that we worked on",
      "segments": [
        {
          "text": "called cluster network, compute cluster setup in OCI.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "The third part of the feature that we worked on",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_038.wav": {
      "chunk_id": "039",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: and all of this we're going to see a demo quickly but i'm going to just spend maybe five more minutes",
      "segments": [
        {
          "text": "and all of this we're going to see a demo quickly but i'm going to just spend maybe five more minutes",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_039.wav": {
      "chunk_id": "040",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: and then go to the demo.\n[2025-06-01 19:13:26] Speaker 5: Is it team level tracking?\n[2025-06-01 19:13:27] Speaker 5: You can create team level tracking.",
      "segments": [
        {
          "text": "and then go to the demo.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Is it team level tracking?",
          "timestamp": "2025-06-01 19:13:26",
          "speaker": "Speaker 5"
        },
        {
          "text": "You can create team level tracking.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_040.wav": {
      "chunk_id": "041",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: handpicking whichever nodes are part of this experiment.\n[2025-06-01 19:13:29] Speaker 5: We are also working towards...",
      "segments": [
        {
          "text": "handpicking whichever nodes are part of this experiment.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "We are also working towards...",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_041.wav": {
      "chunk_id": "042",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: automatically fetching the nodes that are running experiment based on Kubernetes\n[2025-06-01 19:13:29] Speaker 5: how the job system.",
      "segments": [
        {
          "text": "automatically fetching the nodes that are running experiment based on Kubernetes",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "how the job system.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_042.wav": {
      "chunk_id": "043",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: scheduled. So that's another area we're working on automatically, dynamically pulling the nodes that",
      "segments": [
        {
          "text": "scheduled. So that's another area we're working on automatically, dynamically pulling the nodes that",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_043.wav": {
      "chunk_id": "044",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: part of that experiment rather than you allocating what compute nodes go to.\n[2025-06-01 19:13:31] Speaker 5: This I've already said.",
      "segments": [
        {
          "text": "part of that experiment rather than you allocating what compute nodes go to.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "This I've already said.",
          "timestamp": "2025-06-01 19:13:31",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_044.wav": {
      "chunk_id": "045",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: already have both of them running and i'm going to show you that uh the difference between what we do",
      "segments": [
        {
          "text": "already have both of them running and i'm going to show you that uh the difference between what we do",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_045.wav": {
      "chunk_id": "046",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: with performance monitoring and health check is we go very close to the layers that an ML engineer would",
      "segments": [
        {
          "text": "with performance monitoring and health check is we go very close to the layers that an ML engineer would",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_046.wav": {
      "chunk_id": "047",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: operate under, which is PyTorch for us, PyTorch and JAX primarily, right? So we picked up PyTorch base.",
      "segments": [
        {
          "text": "operate under, which is PyTorch for us, PyTorch and JAX primarily, right? So we picked up PyTorch base.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_047.wav": {
      "chunk_id": "048",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: matmal and linear regression based performance testing to achieve how many flops did we achieve",
      "segments": [
        {
          "text": "matmal and linear regression based performance testing to achieve how many flops did we achieve",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_048.wav": {
      "chunk_id": "049",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: on this compute node how much is each gpu performing and is it is it within the threshold of",
      "segments": [
        {
          "text": "on this compute node how much is each gpu performing and is it is it within the threshold of",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_049.wav": {
      "chunk_id": "050",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: the specification from NVIDIA or AMD what we have traditionally seen. So we have a baseline.",
      "segments": [
        {
          "text": "the specification from NVIDIA or AMD what we have traditionally seen. So we have a baseline.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_050.wav": {
      "chunk_id": "051",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: that we score the performance to because it's the standard set of precision based testing either FBA.",
      "segments": [
        {
          "text": "that we score the performance to because it's the standard set of precision based testing either FBA.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_051.wav": {
      "chunk_id": "052",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: FP16, FP32, it automatically does all of this. And most of this code, by the way, for the health",
      "segments": [
        {
          "text": "FP16, FP32, it automatically does all of this. And most of this code, by the way, for the health",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_052.wav": {
      "chunk_id": "053",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: will all be open source so you can see you can change the things if you like or add to it",
      "segments": [
        {
          "text": "will all be open source so you can see you can change the things if you like or add to it",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_053.wav": {
      "chunk_id": "054",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: right and please feel free to contribute to it too.\n[2025-06-01 19:13:28] Speaker 5: This you've seen it.\n[2025-06-01 19:13:30] Speaker 5: The approach we have taken.",
      "segments": [
        {
          "text": "right and please feel free to contribute to it too.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "This you've seen it.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        },
        {
          "text": "The approach we have taken.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_054.wav": {
      "chunk_id": "055",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: here is instead of asking you to poke holes in your existing cluster or networks, we basically push the",
      "segments": [
        {
          "text": "here is instead of asking you to poke holes in your existing cluster or networks, we basically push the",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_055.wav": {
      "chunk_id": "056",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: metrics and we push the health check data to the Prometheus and our central control plane.",
      "segments": [
        {
          "text": "metrics and we push the health check data to the Prometheus and our central control plane.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_056.wav": {
      "chunk_id": "057",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: It could be looked at as, oh, I need to open this port, that port, no exception.",
      "segments": [
        {
          "text": "It could be looked at as, oh, I need to open this port, that port, no exception.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_057.wav": {
      "chunk_id": "058",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: if you're in a vc and in a production environment where everything is locked down egress is usually",
      "segments": [
        {
          "text": "if you're in a vc and in a production environment where everything is locked down egress is usually",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_058.wav": {
      "chunk_id": "059",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: easier and you can always sniff the egress but these are all running within your own tenancy so",
      "segments": [
        {
          "text": "easier and you can always sniff the egress but these are all running within your own tenancy so",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_059.wav": {
      "chunk_id": "060",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: So the origination of all of the metrics to where it's being sent is all within your network.",
      "segments": [
        {
          "text": "So the origination of all of the metrics to where it's being sent is all within your network.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_060.wav": {
      "chunk_id": "061",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: nothing is going into the public. All right. So I'm going to go over this.",
      "segments": [
        {
          "text": "nothing is going into the public. All right. So I'm going to go over this.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_061.wav": {
      "chunk_id": "062",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: but there are plenty of metrics, just a lot.\n[2025-06-01 19:13:28] Speaker 5: And it's kind of an eye candy chart on Grafana's to look.",
      "segments": [
        {
          "text": "but there are plenty of metrics, just a lot.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "And it's kind of an eye candy chart on Grafana's to look.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_062.wav": {
      "chunk_id": "063",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: at but i think you get the point right you have full nvidia dcgm exporter all metrics",
      "segments": [
        {
          "text": "at but i think you get the point right you have full nvidia dcgm exporter all metrics",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_063.wav": {
      "chunk_id": "064",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: You have all AMD SMI metrics.\n[2025-06-01 19:13:27] Speaker 5: You have all of the RDMA metrics that is particularly on our ROC.",
      "segments": [
        {
          "text": "You have all AMD SMI metrics.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "You have all of the RDMA metrics that is particularly on our ROC.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_064.wav": {
      "chunk_id": "065",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: implementation that we sniffed the melanocs drivers for to capture that front end next",
      "segments": [
        {
          "text": "implementation that we sniffed the melanocs drivers for to capture that front end next",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_065.wav": {
      "chunk_id": "066",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: node health is included, health check, full check is included,\n[2025-06-01 19:13:29] Speaker 5: and the traditional disk IO usage.",
      "segments": [
        {
          "text": "node health is included, health check, full check is included,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "and the traditional disk IO usage.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_066.wav": {
      "chunk_id": "067",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: all of those that you usually get with Prometheus already included.\n[2025-06-01 19:13:28] Speaker 5: So all of these is bundled as one.",
      "segments": [
        {
          "text": "all of those that you usually get with Prometheus already included.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "So all of these is bundled as one.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_067.wav": {
      "chunk_id": "068",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: unpacking.",
      "segments": [
        {
          "text": "unpacking.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_068.wav": {
      "chunk_id": "069",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: On the health checks piece, these are all the tests we do today and we'll continue to add more or adjust.",
      "segments": [
        {
          "text": "On the health checks piece, these are all the tests we do today and we'll continue to add more or adjust.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_069.wav": {
      "chunk_id": "070",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: based on how performance we see we do extensive benchmarking to see where the threshold should",
      "segments": [
        {
          "text": "based on how performance we see we do extensive benchmarking to see where the threshold should",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_070.wav": {
      "chunk_id": "071",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: be or the baseline should be and then we either go up and down based on how we are seeing.",
      "segments": [
        {
          "text": "be or the baseline should be and then we either go up and down based on how we are seeing.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_071.wav": {
      "chunk_id": "072",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: example the what should be the ideal mfu on a 140 gb against b200 or mi300x right and then we we lower it",
      "segments": [
        {
          "text": "example the what should be the ideal mfu on a 140 gb against b200 or mi300x right and then we we lower it",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_072.wav": {
      "chunk_id": "073",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: if needed right so but we work with our vendors to also see if this we already doing the right way or not",
      "segments": [
        {
          "text": "if needed right so but we work with our vendors to also see if this we already doing the right way or not",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_073.wav": {
      "chunk_id": "074",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: So here are all the checks we run.\n[2025-06-01 19:13:27] Speaker 5: And all of these, once they complete, you will see a...",
      "segments": [
        {
          "text": "So here are all the checks we run.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "And all of these, once they complete, you will see a...",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_074.wav": {
      "chunk_id": "075",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: metrics flowing through Grafana and you'll also see this.",
      "segments": [
        {
          "text": "metrics flowing through Grafana and you'll also see this.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_075.wav": {
      "chunk_id": "076",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Very simple. This is how the architecture is. I'm not going to spend too much time here either.",
      "segments": [
        {
          "text": "Very simple. This is how the architecture is. I'm not going to spend too much time here either.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_076.wav": {
      "chunk_id": "077",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: because we are evolving how this is going to go right now the way we will release it is this will",
      "segments": [
        {
          "text": "because we are evolving how this is going to go right now the way we will release it is this will",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_077.wav": {
      "chunk_id": "078",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: deploy as a we're not a kubernetes operator yet but you have to basically deploy a dedicated",
      "segments": [
        {
          "text": "deploy as a we're not a kubernetes operator yet but you have to basically deploy a dedicated",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_078.wav": {
      "chunk_id": "079",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: OKE cluster with just CPU nodes, which installs Prometheus Grafana open source and our control.",
      "segments": [
        {
          "text": "OKE cluster with just CPU nodes, which installs Prometheus Grafana open source and our control.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_079.wav": {
      "chunk_id": "080",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: plane api as well as portal right those are all the components that come as part of this",
      "segments": [
        {
          "text": "plane api as well as portal right those are all the components that come as part of this",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_080.wav": {
      "chunk_id": "081",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: And this is that footprint.\n[2025-06-01 19:13:27] Speaker 5: We run a local Postgres for Profana storage.\n[2025-06-01 19:13:30] Speaker 5: We also use Postgres for...",
      "segments": [
        {
          "text": "And this is that footprint.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "We run a local Postgres for Profana storage.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        },
        {
          "text": "We also use Postgres for...",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_081.wav": {
      "chunk_id": "082",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: kind of operating these things.\n[2025-06-01 19:13:27] Speaker 5: This is our kind of MVP minus one approach, right?\n[2025-06-01 19:13:32] Speaker 5: And once this...",
      "segments": [
        {
          "text": "kind of operating these things.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "This is our kind of MVP minus one approach, right?",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        },
        {
          "text": "And once this...",
          "timestamp": "2025-06-01 19:13:32",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_082.wav": {
      "chunk_id": "083",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: becomes a service this will start looking differently any questions so far",
      "segments": [
        {
          "text": "becomes a service this will start looking differently any questions so far",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_083.wav": {
      "chunk_id": "084",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: I have a few questions.\n[2025-06-01 19:13:26] Speaker 1: Do you prefer we wait till the end?",
      "segments": [
        {
          "text": "I have a few questions.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "Do you prefer we wait till the end?",
          "timestamp": "2025-06-01 19:13:26",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_084.wav": {
      "chunk_id": "085",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Yeah, let's take it, Zizal.\n[2025-06-01 19:13:26] Speaker 5: Or if you want to see the demo and then ask those questions, it's up to you.",
      "segments": [
        {
          "text": "Yeah, let's take it, Zizal.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Or if you want to see the demo and then ask those questions, it's up to you.",
          "timestamp": "2025-06-01 19:13:26",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_085.wav": {
      "chunk_id": "086",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: I guess let's do the demo and then we can come back to questions.\n[2025-06-01 19:13:28] Speaker 1: Maybe that will answer some of it.",
      "segments": [
        {
          "text": "I guess let's do the demo and then we can come back to questions.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "Maybe that will answer some of it.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_086.wav": {
      "chunk_id": "087",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: questions perfect yep all right so the the way we we know you can install this is we you will",
      "segments": [
        {
          "text": "questions perfect yep all right so the the way we we know you can install this is we you will",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_087.wav": {
      "chunk_id": "088",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: have a GitHub repo where it could go and say deploy this and it sets up a Kubernetes cluster.",
      "segments": [
        {
          "text": "have a GitHub repo where it could go and say deploy this and it sets up a Kubernetes cluster.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_088.wav": {
      "chunk_id": "089",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Kubernetes cluster setup and all of the Grafana Prometeas,\n[2025-06-01 19:13:29] Speaker 5: everything is installed.",
      "segments": [
        {
          "text": "Kubernetes cluster setup and all of the Grafana Prometeas,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "everything is installed.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_089.wav": {
      "chunk_id": "090",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: in your primary OSID or your tenancy region,\n[2025-06-01 19:13:29] Speaker 5: you will get access to a portal like this.",
      "segments": [
        {
          "text": "in your primary OSID or your tenancy region,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "you will get access to a portal like this.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_090.wav": {
      "chunk_id": "091",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: right we call it corino lens but it is basically the lens so once you are here",
      "segments": [
        {
          "text": "right we call it corino lens but it is basically the lens so once you are here",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_091.wav": {
      "chunk_id": "092",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: right it will go it has the ability to do a multi-region query in a single api",
      "segments": [
        {
          "text": "right it will go it has the ability to do a multi-region query in a single api",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_092.wav": {
      "chunk_id": "093",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: So everything is API first, you have portal and there is a REST API endpoint you can interact.",
      "segments": [
        {
          "text": "So everything is API first, you have portal and there is a REST API endpoint you can interact.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_093.wav": {
      "chunk_id": "094",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: all of that is deployed in your tenancy so you can lock it down if you like to",
      "segments": [
        {
          "text": "all of that is deployed in your tenancy so you can lock it down if you like to",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_094.wav": {
      "chunk_id": "095",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Right now we run on a public domain just for a demo, but everything in here.\n[2025-06-01 19:13:30] Speaker 5: So if you see here.",
      "segments": [
        {
          "text": "Right now we run on a public domain just for a demo, but everything in here.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "So if you see here.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_095.wav": {
      "chunk_id": "096",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: This is done. If I refresh this page, it's going to come back with",
      "segments": [
        {
          "text": "This is done. If I refresh this page, it's going to come back with",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_096.wav": {
      "chunk_id": "097",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: It's doing all the regions that you have subscribed in your OSIT or Oracle tenancy.",
      "segments": [
        {
          "text": "It's doing all the regions that you have subscribed in your OSIT or Oracle tenancy.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_097.wav": {
      "chunk_id": "098",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Then it comes back and tells you, here are all the instances that I can monitor.\n[2025-06-01 19:13:28] Speaker 5: These are basically...",
      "segments": [
        {
          "text": "Then it comes back and tells you, here are all the instances that I can monitor.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "These are basically...",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_098.wav": {
      "chunk_id": "099",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: just GPU instances that are running okay if you have new instances running you can also add",
      "segments": [
        {
          "text": "just GPU instances that are running okay if you have new instances running you can also add",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_099.wav": {
      "chunk_id": "100",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: what we call kind of plug-in.\n[2025-06-01 19:13:27] Speaker 5: So it's a plug-in model.\n[2025-06-01 19:13:28] Speaker 5: You already say, okay, start monitoring.",
      "segments": [
        {
          "text": "what we call kind of plug-in.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "So it's a plug-in model.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        },
        {
          "text": "You already say, okay, start monitoring.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_100.wav": {
      "chunk_id": "101",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: these to OCI lengths. And so if you look at here, I have Frankfurt and Ashburn machines showing.",
      "segments": [
        {
          "text": "these to OCI lengths. And so if you look at here, I have Frankfurt and Ashburn machines showing.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_101.wav": {
      "chunk_id": "102",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: up and it allows me to combine all of this and say they're all part of the same team or same",
      "segments": [
        {
          "text": "up and it allows me to combine all of this and say they're all part of the same team or same",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_102.wav": {
      "chunk_id": "103",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: experiment or same way i want to monitor and i can create what's called monitoring right",
      "segments": [
        {
          "text": "experiment or same way i want to monitor and i can create what's called monitoring right",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_103.wav": {
      "chunk_id": "104",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: So before I go there, right, how can you start monitoring this?\n[2025-06-01 19:13:29] Speaker 5: If you have an existing instance...",
      "segments": [
        {
          "text": "So before I go there, right, how can you start monitoring this?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "If you have an existing instance...",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_104.wav": {
      "chunk_id": "105",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: running or a new instance being provisioned you have to just include this script for now right",
      "segments": [
        {
          "text": "running or a new instance being provisioned you have to just include this script for now right",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_105.wav": {
      "chunk_id": "106",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: we will we will change the way it is we're going to make it a native oci plugin",
      "segments": [
        {
          "text": "we will we will change the way it is we're going to make it a native oci plugin",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_106.wav": {
      "chunk_id": "107",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: once we upstream all of this to our plugin framework.\n[2025-06-01 19:13:27] Speaker 5: But for now, it's basically a tarz file.",
      "segments": [
        {
          "text": "once we upstream all of this to our plugin framework.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "But for now, it's basically a tarz file.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_107.wav": {
      "chunk_id": "108",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: and it's a Golang-based code primarily.\n[2025-06-01 19:13:28] Speaker 5: The health checks are all Python-based.",
      "segments": [
        {
          "text": "and it's a Golang-based code primarily.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "The health checks are all Python-based.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_108.wav": {
      "chunk_id": "109",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: And this is basically end of the day, just all these metrics are composed and pushed.",
      "segments": [
        {
          "text": "And this is basically end of the day, just all these metrics are composed and pushed.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_109.wav": {
      "chunk_id": "110",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: through Prometheus Push gateway,\n[2025-06-01 19:13:27] Speaker 5: which is getting scraped by Push.\n[2025-06-01 19:13:28] Speaker 5: So architecture.",
      "segments": [
        {
          "text": "through Prometheus Push gateway,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "which is getting scraped by Push.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        },
        {
          "text": "So architecture.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_110.wav": {
      "chunk_id": "111",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: this is nothing very different or rocket science here right so it's very simple",
      "segments": [
        {
          "text": "this is nothing very different or rocket science here right so it's very simple",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_111.wav": {
      "chunk_id": "112",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: straightforward, but what it runs and how it runs is what the value we are adding.",
      "segments": [
        {
          "text": "straightforward, but what it runs and how it runs is what the value we are adding.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_112.wav": {
      "chunk_id": "113",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: This is like a cloud in its script as well.\n[2025-06-01 19:13:27] Speaker 5: You can add it as part of a new provisioning.",
      "segments": [
        {
          "text": "This is like a cloud in its script as well.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "You can add it as part of a new provisioning.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_113.wav": {
      "chunk_id": "114",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: instance automatically every new instance that comes up has monitoring enabled and everything is",
      "segments": [
        {
          "text": "instance automatically every new instance that comes up has monitoring enabled and everything is",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_114.wav": {
      "chunk_id": "115",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: running at the host level as a system service it's not operating at the kubernetes layers or at the",
      "segments": [
        {
          "text": "running at the host level as a system service it's not operating at the kubernetes layers or at the",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_115.wav": {
      "chunk_id": "116",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: the Slurm application layers.\n[2025-06-01 19:13:27] Speaker 5: It's running directly on the bare metal host.\n[2025-06-01 19:13:30] Speaker 5: And we felt that was.",
      "segments": [
        {
          "text": "the Slurm application layers.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "It's running directly on the bare metal host.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        },
        {
          "text": "And we felt that was.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_116.wav": {
      "chunk_id": "117",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: the ideal way and the right place for us to remove specific implementations to Kubernetes.",
      "segments": [
        {
          "text": "the ideal way and the right place for us to remove specific implementations to Kubernetes.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_117.wav": {
      "chunk_id": "118",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: or Slurm or others.\n[2025-06-01 19:13:28] Speaker 5: So we can also scan Kubernetes clusters you have running\n[2025-06-01 19:13:31] Speaker 5: or you have RDMA.",
      "segments": [
        {
          "text": "or Slurm or others.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "So we can also scan Kubernetes clusters you have running",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        },
        {
          "text": "or you have RDMA.",
          "timestamp": "2025-06-01 19:13:31",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_118.wav": {
      "chunk_id": "119",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: cluster networks or what we call compute clusters and allow you to also monitor that.",
      "segments": [
        {
          "text": "cluster networks or what we call compute clusters and allow you to also monitor that.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_119.wav": {
      "chunk_id": "120",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: And when you check the whole Kubernetes cluster, all the GPU nodes under it are automatically\n[2025-06-01 19:13:30] Speaker 5: scanned.",
      "segments": [
        {
          "text": "And when you check the whole Kubernetes cluster, all the GPU nodes under it are automatically",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "scanned.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_120.wav": {
      "chunk_id": "121",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: and add it to the monitoring for us.\n[2025-06-01 19:13:27] Speaker 5: That's the experience.\n[2025-06-01 19:13:30] Speaker 5: Okay.\n[2025-06-01 19:13:30] Speaker 5: So I'll quickly show you how...",
      "segments": [
        {
          "text": "and add it to the monitoring for us.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "That's the experience.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        },
        {
          "text": "Okay.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        },
        {
          "text": "So I'll quickly show you how...",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_121.wav": {
      "chunk_id": "122",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: you know this this is basically a bare minimum um portal uh access we have everything is api",
      "segments": [
        {
          "text": "you know this this is basically a bare minimum um portal uh access we have everything is api",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_122.wav": {
      "chunk_id": "123",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: first so you get exactly what you're doing here you could you could do that uh through",
      "segments": [
        {
          "text": "first so you get exactly what you're doing here you could you could do that uh through",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_123.wav": {
      "chunk_id": "124",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: REST API endpoints. So once this loads up, because it's doing like a close to 10 region query,",
      "segments": [
        {
          "text": "REST API endpoints. So once this loads up, because it's doing like a close to 10 region query,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_124.wav": {
      "chunk_id": "125",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: takes roughly six seconds but six to ten seconds we will we'll make it better with some cash",
      "segments": [
        {
          "text": "takes roughly six seconds but six to ten seconds we will we'll make it better with some cash",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_125.wav": {
      "chunk_id": "126",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: So, yeah, no, we have close to 30, 30 plus machines, right, Joleta?\n[2025-06-01 19:13:33] Speaker 5: I think it's performing.",
      "segments": [
        {
          "text": "So, yeah, no, we have close to 30, 30 plus machines, right, Joleta?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "I think it's performing.",
          "timestamp": "2025-06-01 19:13:33",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_126.wav": {
      "chunk_id": "127",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: okay but you know joletta is working hard to see how she can do parallel um parallelization",
      "segments": [
        {
          "text": "okay but you know joletta is working hard to see how she can do parallel um parallelization",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_127.wav": {
      "chunk_id": "128",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: of some of these runs and get back.\n[2025-06-01 19:13:27] Speaker 5: But we got them better.\n[2025-06-01 19:13:29] Speaker 5: We started from 30 seconds.",
      "segments": [
        {
          "text": "of some of these runs and get back.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "But we got them better.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        },
        {
          "text": "We started from 30 seconds.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_128.wav": {
      "chunk_id": "129",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: by now at six seconds, but we'll keep pushing.\n[2025-06-01 19:13:29] Speaker 5: All right. So it allows me to create a...",
      "segments": [
        {
          "text": "by now at six seconds, but we'll keep pushing.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "All right. So it allows me to create a...",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_129.wav": {
      "chunk_id": "130",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: monitoring ring, it's like just an arbitrary way for you to\n[2025-06-01 19:13:28] Speaker 5: combine these resources and say",
      "segments": [
        {
          "text": "monitoring ring, it's like just an arbitrary way for you to",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "combine these resources and say",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_130.wav": {
      "chunk_id": "131",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: I want a dedicated dashboard for this,\n[2025-06-01 19:13:27] Speaker 5: these set of machines, right?\n[2025-06-01 19:13:29] Speaker 5: That's what you.",
      "segments": [
        {
          "text": "I want a dedicated dashboard for this,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "these set of machines, right?",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        },
        {
          "text": "That's what you.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_131.wav": {
      "chunk_id": "132",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: allows you to create a ring and if you go to monitoring rings here and you have OK,\n[2025-06-01 19:13:30] Speaker 5: this is.",
      "segments": [
        {
          "text": "allows you to create a ring and if you go to monitoring rings here and you have OK,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "this is.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_132.wav": {
      "chunk_id": "133",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: for ML training, this is for the team, this is for cost center, whatever, however you",
      "segments": [
        {
          "text": "for ML training, this is for the team, this is for cost center, whatever, however you",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_133.wav": {
      "chunk_id": "134",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: want to use this for kind of bundling all the things. Right? And the thing about",
      "segments": [
        {
          "text": "want to use this for kind of bundling all the things. Right? And the thing about",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_134.wav": {
      "chunk_id": "135",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: this is you can always come back and add more instances or remove the instances if they go",
      "segments": [
        {
          "text": "this is you can always come back and add more instances or remove the instances if they go",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_135.wav": {
      "chunk_id": "136",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: offline or you have to turn back in whatever right so so every every ring you create monitor",
      "segments": [
        {
          "text": "offline or you have to turn back in whatever right so so every every ring you create monitor",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_136.wav": {
      "chunk_id": "137",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: ring you create comes with a dedicated Grafana board which includes all the hosts that are",
      "segments": [
        {
          "text": "ring you create comes with a dedicated Grafana board which includes all the hosts that are",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_137.wav": {
      "chunk_id": "138",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: part of this and I'm going to click you through the Grafana.\n[2025-06-01 19:13:31] Speaker 5: So what you see here at the first part of",
      "segments": [
        {
          "text": "part of this and I'm going to click you through the Grafana.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "So what you see here at the first part of",
          "timestamp": "2025-06-01 19:13:31",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_138.wav": {
      "chunk_id": "139",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: this is the health summary of all the compute nodes that are part of this, right? So we added more nodes.",
      "segments": [
        {
          "text": "this is the health summary of all the compute nodes that are part of this, right? So we added more nodes.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_139.wav": {
      "chunk_id": "140",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: which you're in this part just to show you demo, right?\n[2025-06-01 19:13:27] Speaker 5: So if you see the first board here is this is the.",
      "segments": [
        {
          "text": "which you're in this part just to show you demo, right?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "So if you see the first board here is this is the.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_140.wav": {
      "chunk_id": "141",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: actual health check of all the performance related checks that we did on the host when you activate",
      "segments": [
        {
          "text": "actual health check of all the performance related checks that we did on the host when you activate",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_141.wav": {
      "chunk_id": "142",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: the plugin we will also allow you to run these on demand so if you look at the categories here",
      "segments": [
        {
          "text": "the plugin we will also allow you to run these on demand so if you look at the categories here",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_142.wav": {
      "chunk_id": "143",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: compute throughput, temperature check, all these check, check, check,\n[2025-06-01 19:13:28] Speaker 5: model MFU based stuff.",
      "segments": [
        {
          "text": "compute throughput, temperature check, all these check, check, check,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "model MFU based stuff.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_143.wav": {
      "chunk_id": "144",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: All of those are readily available for you and we will very soon have a link that will exactly take",
      "segments": [
        {
          "text": "All of those are readily available for you and we will very soon have a link that will exactly take",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_144.wav": {
      "chunk_id": "145",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: you to a JSON that is very much deeper on all the tests. This is basically the JSON that the health check.",
      "segments": [
        {
          "text": "you to a JSON that is very much deeper on all the tests. This is basically the JSON that the health check.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_145.wav": {
      "chunk_id": "146",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: script create like what's the bandwidth achieved the tflops achieved for each of the node which",
      "segments": [
        {
          "text": "script create like what's the bandwidth achieved the tflops achieved for each of the node which",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_146.wav": {
      "chunk_id": "147",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: GPU ran this for example right this is the GPU ID of an H100 we ran this is actually the JSON document",
      "segments": [
        {
          "text": "GPU ran this for example right this is the GPU ID of an H100 we ran this is actually the JSON document",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_147.wav": {
      "chunk_id": "148",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: you'll have access to this as well as the logs piece uh but in a grafana it looks",
      "segments": [
        {
          "text": "you'll have access to this as well as the logs piece uh but in a grafana it looks",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_148.wav": {
      "chunk_id": "149",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Now, it's an easier way for you to digest all of this.\n[2025-06-01 19:13:27] Speaker 5: Let me put it up.",
      "segments": [
        {
          "text": "Now, it's an easier way for you to digest all of this.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Let me put it up.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_149.wav": {
      "chunk_id": "150",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: end of the day it's the same data but everything is a very detailed data that you may",
      "segments": [
        {
          "text": "end of the day it's the same data but everything is a very detailed data that you may",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_150.wav": {
      "chunk_id": "151",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: be looking for um than just a summary like this okay both are available okay so we will add more",
      "segments": [
        {
          "text": "be looking for um than just a summary like this okay both are available okay so we will add more",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_151.wav": {
      "chunk_id": "152",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: filters when it allows you to you know go by region and check the gpu types if you have mi300x",
      "segments": [
        {
          "text": "filters when it allows you to you know go by region and check the gpu types if you have mi300x",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_152.wav": {
      "chunk_id": "153",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: So Osaka does not have, maybe I think other machines in Chicago have MI300X.",
      "segments": [
        {
          "text": "So Osaka does not have, maybe I think other machines in Chicago have MI300X.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_153.wav": {
      "chunk_id": "154",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: see here yes you can see my 300x instance um so yeah these are all of both uh my 300x",
      "segments": [
        {
          "text": "see here yes you can see my 300x instance um so yeah these are all of both uh my 300x",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_154.wav": {
      "chunk_id": "155",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: as well as GPU from NVidia are fully monitored.\n[2025-06-01 19:13:29] Speaker 5: And we have health checks running for both.",
      "segments": [
        {
          "text": "as well as GPU from NVidia are fully monitored.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "And we have health checks running for both.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_155.wav": {
      "chunk_id": "156",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Okay, so all of this is the data that you may be interested in.",
      "segments": [
        {
          "text": "Okay, so all of this is the data that you may be interested in.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_156.wav": {
      "chunk_id": "157",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: that allows you to kind of baseline and benchmark all of this. Okay. So all of these metrics are",
      "segments": [
        {
          "text": "that allows you to kind of baseline and benchmark all of this. Okay. So all of these metrics are",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_157.wav": {
      "chunk_id": "158",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: natively available in Prometheus and if I have to show you so we push with OCI",
      "segments": [
        {
          "text": "natively available in Prometheus and if I have to show you so we push with OCI",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_158.wav": {
      "chunk_id": "159",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: lens labels to this and this will allow you to extend it any further you like.",
      "segments": [
        {
          "text": "lens labels to this and this will allow you to extend it any further you like.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_159.wav": {
      "chunk_id": "160",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: custom boards if you like, or you want to merge left join, right join some datasets here to get to more.",
      "segments": [
        {
          "text": "custom boards if you like, or you want to merge left join, right join some datasets here to get to more.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_160.wav": {
      "chunk_id": "161",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: details everything is fully available that's just native krafanov right this is the lcl lens",
      "segments": [
        {
          "text": "details everything is fully available that's just native krafanov right this is the lcl lens",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_161.wav": {
      "chunk_id": "162",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: health check stuff too. There is quite a bit of\n[2025-06-01 19:13:31] Speaker 5: health. Yeah, this is the health summary.",
      "segments": [
        {
          "text": "health check stuff too. There is quite a bit of",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "health. Yeah, this is the health summary.",
          "timestamp": "2025-06-01 19:13:31",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_162.wav": {
      "chunk_id": "163",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: So all of these metrics, the only thing that we are adding,\n[2025-06-01 19:13:27] Speaker 5: this comes out as OCI lens.",
      "segments": [
        {
          "text": "So all of these metrics, the only thing that we are adding,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "this comes out as OCI lens.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_163.wav": {
      "chunk_id": "164",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: anything that comes directly from the vendor,\n[2025-06-01 19:13:26] Speaker 5: like AMD or NVIDIA come as is, right?\n[2025-06-01 19:13:29] Speaker 5: DCGM append it.",
      "segments": [
        {
          "text": "anything that comes directly from the vendor,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "like AMD or NVIDIA come as is, right?",
          "timestamp": "2025-06-01 19:13:26",
          "speaker": "Speaker 5"
        },
        {
          "text": "DCGM append it.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_164.wav": {
      "chunk_id": "165",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: So one additional thing we also did is if you know, let me go back here.",
      "segments": [
        {
          "text": "So one additional thing we also did is if you know, let me go back here.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_165.wav": {
      "chunk_id": "166",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: So this is the overall health board.\n[2025-06-01 19:13:28] Speaker 5: And there's another board that we bring is this is.",
      "segments": [
        {
          "text": "So this is the overall health board.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "And there's another board that we bring is this is.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_166.wav": {
      "chunk_id": "167",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: per host data right this is the actual gpu rdma metrics uh you know you know node health and all",
      "segments": [
        {
          "text": "per host data right this is the actual gpu rdma metrics uh you know you know node health and all",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_167.wav": {
      "chunk_id": "168",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: that. Additional things that we are trying to add is if you come here and look at this table.",
      "segments": [
        {
          "text": "that. Additional things that we are trying to add is if you come here and look at this table.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_168.wav": {
      "chunk_id": "169",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: We will improve the UI a little bit,\n[2025-06-01 19:13:27] Speaker 5: but there is something called host metadata survey.",
      "segments": [
        {
          "text": "We will improve the UI a little bit,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "but there is something called host metadata survey.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_169.wav": {
      "chunk_id": "170",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: It's basically a local service endpoint that we hit\n[2025-06-01 19:13:28] Speaker 5: and we fetch the serial number because if the-",
      "segments": [
        {
          "text": "It's basically a local service endpoint that we hit",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "and we fetch the serial number because if the-",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_170.wav": {
      "chunk_id": "171",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: host is underperforming and you have to turn back it in for repair.\n[2025-06-01 19:13:29] Speaker 5: You know, some data that we have.",
      "segments": [
        {
          "text": "host is underperforming and you have to turn back it in for repair.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "You know, some data that we have.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_171.wav": {
      "chunk_id": "172",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: going to publish here is going to be super helpful.\n[2025-06-01 19:13:27] Speaker 5: And we are looking at how to put an agent.",
      "segments": [
        {
          "text": "going to publish here is going to be super helpful.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "And we are looking at how to put an agent.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_172.wav": {
      "chunk_id": "173",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: AI on top of this, right? Let's\n[2025-06-01 19:13:26] Speaker 5: shortcut that, right? So we\n[2025-06-01 19:13:28] Speaker 5: will instead of throwing more",
      "segments": [
        {
          "text": "AI on top of this, right? Let's",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "shortcut that, right? So we",
          "timestamp": "2025-06-01 19:13:26",
          "speaker": "Speaker 5"
        },
        {
          "text": "will instead of throwing more",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_173.wav": {
      "chunk_id": "174",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: more boards, we will kind of curate an experience where if you see a underperforming node or a bad,",
      "segments": [
        {
          "text": "more boards, we will kind of curate an experience where if you see a underperforming node or a bad,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_174.wav": {
      "chunk_id": "175",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: node. We may automate some of that to see if we could automatically raise a ticket or turn the",
      "segments": [
        {
          "text": "node. We may automate some of that to see if we could automatically raise a ticket or turn the",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_175.wav": {
      "chunk_id": "176",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: machine in or invoke folks in the support team to help you guys out.\n[2025-06-01 19:13:30] Speaker 5: So that's the.",
      "segments": [
        {
          "text": "machine in or invoke folks in the support team to help you guys out.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "So that's the.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_176.wav": {
      "chunk_id": "177",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: future roadmap. So yeah, everything here, we're going to add more stuff like what's the",
      "segments": [
        {
          "text": "future roadmap. So yeah, everything here, we're going to add more stuff like what's the",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_177.wav": {
      "chunk_id": "178",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: the huda driver you're running what's the kernel versions you're running um what's the OS",
      "segments": [
        {
          "text": "the huda driver you're running what's the kernel versions you're running um what's the OS",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_178.wav": {
      "chunk_id": "179",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: attached to, what's the Rockham driver version you're running, all of those data will be fully",
      "segments": [
        {
          "text": "attached to, what's the Rockham driver version you're running, all of those data will be fully",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_179.wav": {
      "chunk_id": "180",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: available everything related to metadata will be published here and you can continue to",
      "segments": [
        {
          "text": "available everything related to metadata will be published here and you can continue to",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_180.wav": {
      "chunk_id": "181",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: use that instead of you SSHing into the machine,\n[2025-06-01 19:13:28] Speaker 5: running some commands and all of that.",
      "segments": [
        {
          "text": "use that instead of you SSHing into the machine,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "running some commands and all of that.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_181.wav": {
      "chunk_id": "182",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: So, readily available.\n[2025-06-01 19:13:27] Speaker 5: Everything else you see here is something you may have been using already.",
      "segments": [
        {
          "text": "So, readily available.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Everything else you see here is something you may have been using already.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_182.wav": {
      "chunk_id": "183",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: which is power, usage, temperature, utilization,\n[2025-06-01 19:13:28] Speaker 5: all that stuff.\n[2025-06-01 19:13:30] Speaker 5: Okay.\n[2025-06-01 19:13:31] Speaker 5: So in an actual, this-",
      "segments": [
        {
          "text": "which is power, usage, temperature, utilization,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "all that stuff.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        },
        {
          "text": "Okay.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        },
        {
          "text": "So in an actual, this-",
          "timestamp": "2025-06-01 19:13:31",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_183.wav": {
      "chunk_id": "184",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: this is this is what it is right so at least our first iteration of um can we get a monitor",
      "segments": [
        {
          "text": "this is this is what it is right so at least our first iteration of um can we get a monitor",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_184.wav": {
      "chunk_id": "185",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: going which is native and health checks going which is what lci published health checks and",
      "segments": [
        {
          "text": "going which is native and health checks going which is what lci published health checks and",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_185.wav": {
      "chunk_id": "186",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: just always vendor specified. So I'm gonna stop here and see if you folks have questions.",
      "segments": [
        {
          "text": "just always vendor specified. So I'm gonna stop here and see if you folks have questions.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_186.wav": {
      "chunk_id": "187",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: and also talk about some feedback if you have for us.\n[2025-06-01 19:13:32] Speaker 1: Thanks for the demo.\n[2025-06-01 19:13:33] Speaker 1: I have a few...",
      "segments": [
        {
          "text": "and also talk about some feedback if you have for us.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Thanks for the demo.",
          "timestamp": "2025-06-01 19:13:32",
          "speaker": "Speaker 1"
        },
        {
          "text": "I have a few...",
          "timestamp": "2025-06-01 19:13:33",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_187.wav": {
      "chunk_id": "188",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: questions um so i think you mentioned in the first slide one of the things being like um you know",
      "segments": [
        {
          "text": "questions um so i think you mentioned in the first slide one of the things being like um you know",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_188.wav": {
      "chunk_id": "189",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: Kubernetes native, cloud native,\n[2025-06-01 19:13:26] Speaker 1: which was one of the things we discussed previously\n[2025-06-01 19:13:28] Speaker 1: as being one of the...",
      "segments": [
        {
          "text": "Kubernetes native, cloud native,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "which was one of the things we discussed previously",
          "timestamp": "2025-06-01 19:13:26",
          "speaker": "Speaker 1"
        },
        {
          "text": "as being one of the...",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_189.wav": {
      "chunk_id": "190",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: key things really important for us um what other levels of integrations with oke are you planning",
      "segments": [
        {
          "text": "key things really important for us um what other levels of integrations with oke are you planning",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_190.wav": {
      "chunk_id": "191",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: at all, if any.\n[2025-06-01 19:13:26] Speaker 1: Things that top of mind would be super helpful\n[2025-06-01 19:13:28] Speaker 1: for us would be being able to",
      "segments": [
        {
          "text": "at all, if any.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "Things that top of mind would be super helpful",
          "timestamp": "2025-06-01 19:13:26",
          "speaker": "Speaker 1"
        },
        {
          "text": "for us would be being able to",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_191.wav": {
      "chunk_id": "192",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: surface some of these unhealthy node conditions to OKE or to the actual Kubernetes object.",
      "segments": [
        {
          "text": "surface some of these unhealthy node conditions to OKE or to the actual Kubernetes object.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_192.wav": {
      "chunk_id": "193",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: so that we can use that in our tooling.\n[2025-06-01 19:13:27] Speaker 1: And then, you know, when we're launching, submitting jobs.",
      "segments": [
        {
          "text": "so that we can use that in our tooling.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "And then, you know, when we're launching, submitting jobs.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_193.wav": {
      "chunk_id": "194",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: being able to detect that a node is unhealthy.\n[2025-06-01 19:13:28] Speaker 1: The other thing I think is like the monitoring.",
      "segments": [
        {
          "text": "being able to detect that a node is unhealthy.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "The other thing I think is like the monitoring.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_194.wav": {
      "chunk_id": "195",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: the rings that you mentioned, I don't think that would be super helpful for us because we're not",
      "segments": [
        {
          "text": "the rings that you mentioned, I don't think that would be super helpful for us because we're not",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_195.wav": {
      "chunk_id": "196",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: assigning nodes to people or teams.\n[2025-06-01 19:13:28] Speaker 1: Instead, we're extremely dynamic.\n[2025-06-01 19:13:31] Speaker 1: So we have...",
      "segments": [
        {
          "text": "assigning nodes to people or teams.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "Instead, we're extremely dynamic.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 1"
        },
        {
          "text": "So we have...",
          "timestamp": "2025-06-01 19:13:31",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_196.wav": {
      "chunk_id": "197",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: you know, super cluster of thousands of GPUs.\n[2025-06-01 19:13:27] Speaker 1: And those nodes get used.\n[2025-06-01 19:13:30] Speaker 1: We use Q, which is a native.",
      "segments": [
        {
          "text": "you know, super cluster of thousands of GPUs.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "And those nodes get used.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 1"
        },
        {
          "text": "We use Q, which is a native.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_197.wav": {
      "chunk_id": "198",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: Kubernetes project to schedule workloads.\n[2025-06-01 19:13:30] Speaker 1: So at any given time, we want to know, like, this",
      "segments": [
        {
          "text": "Kubernetes project to schedule workloads.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "So at any given time, we want to know, like, this",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_198.wav": {
      "chunk_id": "199",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: job is running with, you know, 128 GPUs, are any of the nodes unhealthy in this job? And so that job",
      "segments": [
        {
          "text": "job is running with, you know, 128 GPUs, are any of the nodes unhealthy in this job? And so that job",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_199.wav": {
      "chunk_id": "200",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: might be using a different set of nodes than another job would be for the same team the next",
      "segments": [
        {
          "text": "might be using a different set of nodes than another job would be for the same team the next",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_200.wav": {
      "chunk_id": "201",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: day. So something like that would be helpful. Okay, wonderful. I think for the answer for the first",
      "segments": [
        {
          "text": "day. So something like that would be helpful. Okay, wonderful. I think for the answer for the first",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_201.wav": {
      "chunk_id": "202",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: one is uh we are working with okay team i think okay team also has added some features lately where",
      "segments": [
        {
          "text": "one is uh we are working with okay team i think okay team also has added some features lately where",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_202.wav": {
      "chunk_id": "203",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: they can detect an unhealthy gpu node and start tagging them as unallocatable uh for some some",
      "segments": [
        {
          "text": "they can detect an unhealthy gpu node and start tagging them as unallocatable uh for some some",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_203.wav": {
      "chunk_id": "204",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: the checks that they ran.\n[2025-06-01 19:13:27] Speaker 5: So we are actually working with them\n[2025-06-01 19:13:29] Speaker 5: to see if anything...",
      "segments": [
        {
          "text": "the checks that they ran.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "So we are actually working with them",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        },
        {
          "text": "to see if anything...",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_204.wav": {
      "chunk_id": "205",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: we find in our health check uh that uh that says that you know this node one of the gpus in the",
      "segments": [
        {
          "text": "we find in our health check uh that uh that says that you know this node one of the gpus in the",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_205.wav": {
      "chunk_id": "206",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: node is continuous to underperform and communicate back on unschedulable.",
      "segments": [
        {
          "text": "node is continuous to underperform and communicate back on unschedulable.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_206.wav": {
      "chunk_id": "207",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: we will have that integration point in the future for sure.\n[2025-06-01 19:13:29] Speaker 5: Right. So, and the metrics from.",
      "segments": [
        {
          "text": "we will have that integration point in the future for sure.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Right. So, and the metrics from.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_207.wav": {
      "chunk_id": "208",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: OKE directly. So if there are part level, position volume level and lower",
      "segments": [
        {
          "text": "OKE directly. So if there are part level, position volume level and lower",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_208.wav": {
      "chunk_id": "209",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: of good healthy prometheus metrics that come we can directly pipe all of those into this lens with",
      "segments": [
        {
          "text": "of good healthy prometheus metrics that come we can directly pipe all of those into this lens with",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_209.wav": {
      "chunk_id": "210",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: added set of things from our side to kind of consolidate and give you that one view that means",
      "segments": [
        {
          "text": "added set of things from our side to kind of consolidate and give you that one view that means",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_210.wav": {
      "chunk_id": "211",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: be needed. So that definitely is the plan, but we are looking into, okay, now a customer has to run.",
      "segments": [
        {
          "text": "be needed. So that definitely is the plan, but we are looking into, okay, now a customer has to run.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_211.wav": {
      "chunk_id": "212",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: a Prometheus instance in a Kubernetes cluster and that complication is what we're trying to do.",
      "segments": [
        {
          "text": "a Prometheus instance in a Kubernetes cluster and that complication is what we're trying to do.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_212.wav": {
      "chunk_id": "213",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: tackle the next feature set.\n[2025-06-01 19:13:29] Speaker 1: Okay, makes sense.\n[2025-06-01 19:13:30] Speaker 1: Yeah, just to reemphasize.",
      "segments": [
        {
          "text": "tackle the next feature set.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Okay, makes sense.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 1"
        },
        {
          "text": "Yeah, just to reemphasize.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_213.wav": {
      "chunk_id": "214",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: this is like probably the most important thing for us like really being able to",
      "segments": [
        {
          "text": "this is like probably the most important thing for us like really being able to",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_214.wav": {
      "chunk_id": "215",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: because we want to be able to do this automatically, right?\n[2025-06-01 19:13:28] Speaker 1: If a GPU breaks overnight, we don't want...",
      "segments": [
        {
          "text": "because we want to be able to do this automatically, right?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "If a GPU breaks overnight, we don't want...",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_215.wav": {
      "chunk_id": "216",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: someone to have to, you know, go do something, go look at a Grafana dashboard we want.",
      "segments": [
        {
          "text": "someone to have to, you know, go do something, go look at a Grafana dashboard we want.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_216.wav": {
      "chunk_id": "217",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: our jobs to automatically react to these things.\n[2025-06-01 19:13:28] Speaker 5: Yeah. So I think that that brings another second.",
      "segments": [
        {
          "text": "our jobs to automatically react to these things.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "Yeah. So I think that that brings another second.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_217.wav": {
      "chunk_id": "218",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: question or even feedback you had for us is like the static way of creating monitoring ranks is",
      "segments": [
        {
          "text": "question or even feedback you had for us is like the static way of creating monitoring ranks is",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_218.wav": {
      "chunk_id": "219",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: not ideal we fully hear you uh i think because of the dynamic if you're using q where you know",
      "segments": [
        {
          "text": "not ideal we fully hear you uh i think because of the dynamic if you're using q where you know",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_219.wav": {
      "chunk_id": "220",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: you get it booted out based on what team and priority and cohort and all of those stuff are.",
      "segments": [
        {
          "text": "you get it booted out based on what team and priority and cohort and all of those stuff are.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_220.wav": {
      "chunk_id": "221",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: We will integrate with OKE and the way we will look at is where the job is running or where",
      "segments": [
        {
          "text": "We will integrate with OKE and the way we will look at is where the job is running or where",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_221.wav": {
      "chunk_id": "222",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: the deployment is running at a point of time and try to dynamically what we call add more tags to",
      "segments": [
        {
          "text": "the deployment is running at a point of time and try to dynamically what we call add more tags to",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_222.wav": {
      "chunk_id": "223",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: metadata that's coming in to exactly relate to what experiment who ran it when when did it",
      "segments": [
        {
          "text": "metadata that's coming in to exactly relate to what experiment who ran it when when did it",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_223.wav": {
      "chunk_id": "224",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: complete timestamp it and try to pull those in.\n[2025-06-01 19:13:28] Speaker 5: So it's a thing that we are working.",
      "segments": [
        {
          "text": "complete timestamp it and try to pull those in.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "So it's a thing that we are working.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_224.wav": {
      "chunk_id": "225",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: towards, but we started with more non-Kubernetes-based experience, and then we would quick switch.",
      "segments": [
        {
          "text": "towards, but we started with more non-Kubernetes-based experience, and then we would quick switch.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_225.wav": {
      "chunk_id": "226",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: move into the dynamic workload where we pull in the nodes and even the GPUs, right?\n[2025-06-01 19:13:30] Speaker 5: Not full nodes.",
      "segments": [
        {
          "text": "move into the dynamic workload where we pull in the nodes and even the GPUs, right?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Not full nodes.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_226.wav": {
      "chunk_id": "227",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: be running every experiment so we will try to say four out of that no GPUs were running for this",
      "segments": [
        {
          "text": "be running every experiment so we will try to say four out of that no GPUs were running for this",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_227.wav": {
      "chunk_id": "228",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: experiment and that's what is aggregated into that board.\n[2025-06-01 19:13:28] Speaker 5: We will, that's a good point.",
      "segments": [
        {
          "text": "experiment and that's what is aggregated into that board.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "We will, that's a good point.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_228.wav": {
      "chunk_id": "229",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: feedback and I think we will try to prioritize that.\n[2025-06-01 19:13:27] Speaker 5: Yeah, I think you're not very far from.",
      "segments": [
        {
          "text": "feedback and I think we will try to prioritize that.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Yeah, I think you're not very far from.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_229.wav": {
      "chunk_id": "230",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: that honestly even without having to do like tagging of instances and trying to keep track of",
      "segments": [
        {
          "text": "that honestly even without having to do like tagging of instances and trying to keep track of",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_230.wav": {
      "chunk_id": "231",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: what's running what. I think you could do some queries in your dashboard that just...",
      "segments": [
        {
          "text": "what's running what. I think you could do some queries in your dashboard that just...",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_231.wav": {
      "chunk_id": "232",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: shows like your health metrics and then also use Kubernetes metrics and see like for",
      "segments": [
        {
          "text": "shows like your health metrics and then also use Kubernetes metrics and see like for",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_232.wav": {
      "chunk_id": "233",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: any given job or deployment, like you said, show all the nodes of that job and show if",
      "segments": [
        {
          "text": "any given job or deployment, like you said, show all the nodes of that job and show if",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_233.wav": {
      "chunk_id": "234",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: of them are unhealthy so i think it's just a matter of like tying everything together",
      "segments": [
        {
          "text": "of them are unhealthy so i think it's just a matter of like tying everything together",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_234.wav": {
      "chunk_id": "235",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Yeah, I fully agree. Actually, we started like that, by the way, and I think Joleta and...",
      "segments": [
        {
          "text": "Yeah, I fully agree. Actually, we started like that, by the way, and I think Joleta and...",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_235.wav": {
      "chunk_id": "236",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: and most of my team knows that we started with a full Kubernetes-based experience, but we were nudged.",
      "segments": [
        {
          "text": "and most of my team knows that we started with a full Kubernetes-based experience, but we were nudged.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_236.wav": {
      "chunk_id": "237",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: on like well i think there are a lot of people who want a full monitoring and this is where we",
      "segments": [
        {
          "text": "on like well i think there are a lot of people who want a full monitoring and this is where we",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_237.wav": {
      "chunk_id": "238",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: I think we have the both. We like to just pull it in like you said.",
      "segments": [
        {
          "text": "I think we have the both. We like to just pull it in like you said.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_238.wav": {
      "chunk_id": "239",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: and start relating where, where, what is running\n[2025-06-01 19:13:28] Speaker 5: and start kind of creating that.",
      "segments": [
        {
          "text": "and start relating where, where, what is running",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "and start kind of creating that.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_239.wav": {
      "chunk_id": "240",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: key value pair mapping here.",
      "segments": [
        {
          "text": "key value pair mapping here.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_240.wav": {
      "chunk_id": "241",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: That's another question I'll have and then I'll pass it to like other.",
      "segments": [
        {
          "text": "That's another question I'll have and then I'll pass it to like other.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_241.wav": {
      "chunk_id": "242",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: Luis, Ace, if you have any questions, is you mentioned health checks. Can you talk?",
      "segments": [
        {
          "text": "Luis, Ace, if you have any questions, is you mentioned health checks. Can you talk?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_242.wav": {
      "chunk_id": "243",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: a bit more about um how those would run like are you running anything that requires the workload",
      "segments": [
        {
          "text": "a bit more about um how those would run like are you running anything that requires the workload",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_243.wav": {
      "chunk_id": "244",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: to be idle and if so is it or the gpu note to be idle and if so is it going to be doing",
      "segments": [
        {
          "text": "to be idle and if so is it or the gpu note to be idle and if so is it going to be doing",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_244.wav": {
      "chunk_id": "245",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: something like when nodes go idle to check the gpus or are these like running passively in the background",
      "segments": [
        {
          "text": "something like when nodes go idle to check the gpus or are these like running passively in the background",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_245.wav": {
      "chunk_id": "246",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: So I'll ask Soumya to chime in as well on she's an ML engineer worked on the script.",
      "segments": [
        {
          "text": "So I'll ask Soumya to chime in as well on she's an ML engineer worked on the script.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_246.wav": {
      "chunk_id": "247",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: So we run this, we expect the GPUs to be idle and no workloads to be running.",
      "segments": [
        {
          "text": "So we run this, we expect the GPUs to be idle and no workloads to be running.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_247.wav": {
      "chunk_id": "248",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: this is where the PyTorch is loading into the tensor so it's loading into the accelerator.",
      "segments": [
        {
          "text": "this is where the PyTorch is loading into the tensor so it's loading into the accelerator.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_248.wav": {
      "chunk_id": "249",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: running all these checks and coming back.\n[2025-06-01 19:13:27] Speaker 5: So we expect no workloads to be running when this.",
      "segments": [
        {
          "text": "running all these checks and coming back.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "So we expect no workloads to be running when this.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_249.wav": {
      "chunk_id": "250",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: this is running. We run it when you say you need to run it.\n[2025-06-01 19:13:28] Speaker 5: Right now we have not automated it.",
      "segments": [
        {
          "text": "this is running. We run it when you say you need to run it.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Right now we have not automated it.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_250.wav": {
      "chunk_id": "251",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: And this is where we need feedback.\n[2025-06-01 19:13:26] Speaker 5: Like, do you want to run at midnight, 12 o'clock every day?",
      "segments": [
        {
          "text": "And this is where we need feedback.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Like, do you want to run at midnight, 12 o'clock every day?",
          "timestamp": "2025-06-01 19:13:26",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_251.wav": {
      "chunk_id": "252",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: right you need that kind of no definitely not",
      "segments": [
        {
          "text": "right you need that kind of no definitely not",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_252.wav": {
      "chunk_id": "253",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: Yeah, if I'm an ML engineer, I'm like, okay, I know when my pipeline is at a pause where I say call.",
      "segments": [
        {
          "text": "Yeah, if I'm an ML engineer, I'm like, okay, I know when my pipeline is at a pause where I say call.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_253.wav": {
      "chunk_id": "254",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: of my gpus are flushed out and idle i want to run the health checks for everything and make sure",
      "segments": [
        {
          "text": "of my gpus are flushed out and idle i want to run the health checks for everything and make sure",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_254.wav": {
      "chunk_id": "255",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: of that is good before we go to the next phase, right? Is that an experience you would look for?",
      "segments": [
        {
          "text": "of that is good before we go to the next phase, right? Is that an experience you would look for?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_255.wav": {
      "chunk_id": "256",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: What we are thinking is we will give you a on-demand way for you to invoke health checkscripts.",
      "segments": [
        {
          "text": "What we are thinking is we will give you a on-demand way for you to invoke health checkscripts.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_256.wav": {
      "chunk_id": "257",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: through a REST API.\n[2025-06-01 19:13:26] Speaker 5: You have to just say\n[2025-06-01 19:13:28] Speaker 5: when you want to run it\n[2025-06-01 19:13:30] Speaker 5: and you on-demand run it.",
      "segments": [
        {
          "text": "through a REST API.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "You have to just say",
          "timestamp": "2025-06-01 19:13:26",
          "speaker": "Speaker 5"
        },
        {
          "text": "when you want to run it",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        },
        {
          "text": "and you on-demand run it.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_257.wav": {
      "chunk_id": "258",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Because we don't know when your GPUs are idle, then they're not.",
      "segments": [
        {
          "text": "Because we don't know when your GPUs are idle, then they're not.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_258.wav": {
      "chunk_id": "259",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: Interesting. I was thinking like you might be able to figure that out like from a program.",
      "segments": [
        {
          "text": "Interesting. I was thinking like you might be able to figure that out like from a program.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_259.wav": {
      "chunk_id": "260",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: programmatic standpoint, you might be able to get that data and whenever they are idle.",
      "segments": [
        {
          "text": "programmatic standpoint, you might be able to get that data and whenever they are idle.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_260.wav": {
      "chunk_id": "261",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: kick off like a workload that runs the Huff check.\n[2025-06-01 19:13:30] Speaker 1: So the intuition behind creating",
      "segments": [
        {
          "text": "kick off like a workload that runs the Huff check.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "So the intuition behind creating",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_261.wav": {
      "chunk_id": "262",
      "transcript": "[2025-06-01 19:13:25] Speaker 3: this health check recipe is imagine a machine learning engineer or like you have a team that's",
      "segments": [
        {
          "text": "this health check recipe is imagine a machine learning engineer or like you have a team that's",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 3"
        }
      ],
      "language": "en"
    },
    "chunk_262.wav": {
      "chunk_id": "263",
      "transcript": "[2025-06-01 19:13:25] Speaker 3: going to do a multi-node training or like multi-node fine tuning, right?\n[2025-06-01 19:13:29] Speaker 3: Before you go into doing...",
      "segments": [
        {
          "text": "going to do a multi-node training or like multi-node fine tuning, right?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 3"
        },
        {
          "text": "Before you go into doing...",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 3"
        }
      ],
      "language": "en"
    },
    "chunk_263.wav": {
      "chunk_id": "264",
      "transcript": "[2025-06-01 19:13:25] Speaker 3: a large-scale training operation or like any kind of like workload that's going to take too much",
      "segments": [
        {
          "text": "a large-scale training operation or like any kind of like workload that's going to take too much",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 3"
        }
      ],
      "language": "en"
    },
    "chunk_264.wav": {
      "chunk_id": "265",
      "transcript": "[2025-06-01 19:13:25] Speaker 3: demand of the GPU itself.\n[2025-06-01 19:13:27] Speaker 3: You'd want to run this health check before that to understand that",
      "segments": [
        {
          "text": "demand of the GPU itself.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 3"
        },
        {
          "text": "You'd want to run this health check before that to understand that",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 3"
        }
      ],
      "language": "en"
    },
    "chunk_265.wav": {
      "chunk_id": "266",
      "transcript": "[2025-06-01 19:13:25] Speaker 3: health of your infrastructure right for example the way this health check is designed is it's based",
      "segments": [
        {
          "text": "health of your infrastructure right for example the way this health check is designed is it's based",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 3"
        }
      ],
      "language": "en"
    },
    "chunk_266.wav": {
      "chunk_id": "267",
      "transcript": "[2025-06-01 19:13:25] Speaker 3: on just 10 0 matrix multiplication right so depending upon the matrix size you probably be",
      "segments": [
        {
          "text": "on just 10 0 matrix multiplication right so depending upon the matrix size you probably be",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 3"
        }
      ],
      "language": "en"
    },
    "chunk_267.wav": {
      "chunk_id": "268",
      "transcript": "[2025-06-01 19:13:25] Speaker 3: loading like 818 like imagine like a matrix size of like 8192 by 818",
      "segments": [
        {
          "text": "loading like 818 like imagine like a matrix size of like 8192 by 818",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 3"
        }
      ],
      "language": "en"
    },
    "chunk_268.wav": {
      "chunk_id": "269",
      "transcript": "[2025-06-01 19:13:25] Speaker 3: too right you're going to be loading all these matrix into the gpu memory and we are going to",
      "segments": [
        {
          "text": "too right you're going to be loading all these matrix into the gpu memory and we are going to",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 3"
        }
      ],
      "language": "en"
    },
    "chunk_269.wav": {
      "chunk_id": "270",
      "transcript": "[2025-06-01 19:13:25] Speaker 3: pressurize and see how much your machine is able to take the computation throughput or like throat",
      "segments": [
        {
          "text": "pressurize and see how much your machine is able to take the computation throughput or like throat",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 3"
        }
      ],
      "language": "en"
    },
    "chunk_270.wav": {
      "chunk_id": "271",
      "transcript": "[2025-06-01 19:13:25] Speaker 3: the power and things like that. So ideally you would want to do it when your machine is idle and to",
      "segments": [
        {
          "text": "the power and things like that. So ideally you would want to do it when your machine is idle and to",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 3"
        }
      ],
      "language": "en"
    },
    "chunk_271.wav": {
      "chunk_id": "272",
      "transcript": "[2025-06-01 19:13:25] Speaker 3: address your point yeah we could actually schedule and understand when the jobs are not running",
      "segments": [
        {
          "text": "address your point yeah we could actually schedule and understand when the jobs are not running",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 3"
        }
      ],
      "language": "en"
    },
    "chunk_272.wav": {
      "chunk_id": "273",
      "transcript": "[2025-06-01 19:13:25] Speaker 3: and we could just run the health check at that point.\n[2025-06-01 19:13:27] Speaker 3: And we can detect when the machines are...",
      "segments": [
        {
          "text": "and we could just run the health check at that point.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 3"
        },
        {
          "text": "And we can detect when the machines are...",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 3"
        }
      ],
      "language": "en"
    },
    "chunk_273.wav": {
      "chunk_id": "274",
      "transcript": "[2025-06-01 19:13:25] Speaker 3: Yeah, I think it'd be interesting to have the option to schedule it on demand, like as a...",
      "segments": [
        {
          "text": "Yeah, I think it'd be interesting to have the option to schedule it on demand, like as a...",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 3"
        }
      ],
      "language": "en"
    },
    "chunk_274.wav": {
      "chunk_id": "275",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: we hook like to the jobs like you said um but i don't i need to think more about this",
      "segments": [
        {
          "text": "we hook like to the jobs like you said um but i don't i need to think more about this",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_275.wav": {
      "chunk_id": "276",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: But I think, you know, my intuition is why not both, you know, like having a periodic check.",
      "segments": [
        {
          "text": "But I think, you know, my intuition is why not both, you know, like having a periodic check.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_276.wav": {
      "chunk_id": "277",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: that best effort runs when the node is sitting there doing nothing.\n[2025-06-01 19:13:29] Speaker 1: So that if a node does go unhealthy,",
      "segments": [
        {
          "text": "that best effort runs when the node is sitting there doing nothing.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "So that if a node does go unhealthy,",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_277.wav": {
      "chunk_id": "278",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: we can find out about it early and not wait for a job to get scheduled there to find out.",
      "segments": [
        {
          "text": "we can find out about it early and not wait for a job to get scheduled there to find out.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_278.wav": {
      "chunk_id": "279",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Yeah, no, we'll take it as a good feedback.\n[2025-06-01 19:13:28] Speaker 5: We have still, because we have to think.",
      "segments": [
        {
          "text": "Yeah, no, we'll take it as a good feedback.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "We have still, because we have to think.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_279.wav": {
      "chunk_id": "280",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: through a little bit on scheduling because it takes roughly five minutes for this head check",
      "segments": [
        {
          "text": "through a little bit on scheduling because it takes roughly five minutes for this head check",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_280.wav": {
      "chunk_id": "281",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: to finish and in mix of this if your queue ends up scheduling another job uh they'll they'll",
      "segments": [
        {
          "text": "to finish and in mix of this if your queue ends up scheduling another job uh they'll they'll",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_281.wav": {
      "chunk_id": "282",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: it can't find an ideal GPU. So they go on pending. So we have to just think through this.",
      "segments": [
        {
          "text": "it can't find an ideal GPU. So they go on pending. So we have to just think through this.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_282.wav": {
      "chunk_id": "283",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Yeah, no, this would definitely, yes, this would definitely have to be an...",
      "segments": [
        {
          "text": "Yeah, no, this would definitely, yes, this would definitely have to be an...",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_283.wav": {
      "chunk_id": "284",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: interruptible workload so that our workloads can always schedule the priority.",
      "segments": [
        {
          "text": "interruptible workload so that our workloads can always schedule the priority.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_284.wav": {
      "chunk_id": "285",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Exactly right you cannot boot this workload because this is running at the system",
      "segments": [
        {
          "text": "Exactly right you cannot boot this workload because this is running at the system",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_285.wav": {
      "chunk_id": "286",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: level, right? And Kubernetes layers are at a much higher layer too.",
      "segments": [
        {
          "text": "level, right? And Kubernetes layers are at a much higher layer too.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_286.wav": {
      "chunk_id": "287",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: and we need to think of this a little bit but i think this is really good feedback um thank you",
      "segments": [
        {
          "text": "and we need to think of this a little bit but i think this is really good feedback um thank you",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_287.wav": {
      "chunk_id": "288",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: Yeah, no, thank you.\n[2025-06-01 19:13:26] Speaker 1: Louise Ace, you have anything?",
      "segments": [
        {
          "text": "Yeah, no, thank you.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "Louise Ace, you have anything?",
          "timestamp": "2025-06-01 19:13:26",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_288.wav": {
      "chunk_id": "289",
      "transcript": "[2025-06-01 19:13:25] Speaker 4: Mostly just echoing your thoughts. I mean, when we talk about node lifecycle,",
      "segments": [
        {
          "text": "Mostly just echoing your thoughts. I mean, when we talk about node lifecycle,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 4"
        }
      ],
      "language": "en"
    },
    "chunk_289.wav": {
      "chunk_id": "290",
      "transcript": "[2025-06-01 19:13:25] Speaker 4: It's very much like an ongoing thing.\n[2025-06-01 19:13:26] Speaker 4: It's not sort of a one off thing.\n[2025-06-01 19:13:27] Speaker 4: So just, yeah.",
      "segments": [
        {
          "text": "It's very much like an ongoing thing.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 4"
        },
        {
          "text": "It's not sort of a one off thing.",
          "timestamp": "2025-06-01 19:13:26",
          "speaker": "Speaker 4"
        },
        {
          "text": "So just, yeah.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 4"
        }
      ],
      "language": "en"
    },
    "chunk_290.wav": {
      "chunk_id": "291",
      "transcript": "[2025-06-01 19:13:25] Speaker 4: like having both elements and thinking about how nodes like proceed through.",
      "segments": [
        {
          "text": "like having both elements and thinking about how nodes like proceed through.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 4"
        }
      ],
      "language": "en"
    },
    "chunk_291.wav": {
      "chunk_id": "292",
      "transcript": "[2025-06-01 19:13:25] Speaker 4: I don't want to say this process exactly, but like, I don't know, mostly just echoing Cecile's",
      "segments": [
        {
          "text": "I don't want to say this process exactly, but like, I don't know, mostly just echoing Cecile's",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 4"
        }
      ],
      "language": "en"
    },
    "chunk_292.wav": {
      "chunk_id": "293",
      "transcript": "[2025-06-01 19:13:25] Speaker 4: thoughts. Okay. Yeah. Thank you. So what, what we are trying to also avoid is before you shut this",
      "segments": [
        {
          "text": "thoughts. Okay. Yeah. Thank you. So what, what we are trying to also avoid is before you shut this",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 4"
        }
      ],
      "language": "en"
    },
    "chunk_293.wav": {
      "chunk_id": "294",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: machine and turn it back into OCI to repair. We want to see what is the issue, right?",
      "segments": [
        {
          "text": "machine and turn it back into OCI to repair. We want to see what is the issue, right?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_294.wav": {
      "chunk_id": "295",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: deeper into what where is the concern is it a single gpu always coming back with a lower",
      "segments": [
        {
          "text": "deeper into what where is the concern is it a single gpu always coming back with a lower",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_295.wav": {
      "chunk_id": "296",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: performance compared to the rest seven of them in the same node or is it consistent uh no",
      "segments": [
        {
          "text": "performance compared to the rest seven of them in the same node or is it consistent uh no",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_296.wav": {
      "chunk_id": "297",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: RDMA nick flapping issues, errors that show up.\n[2025-06-01 19:13:28] Speaker 5: And this is a start.\n[2025-06-01 19:13:30] Speaker 5: And where we want to go.",
      "segments": [
        {
          "text": "RDMA nick flapping issues, errors that show up.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "And this is a start.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        },
        {
          "text": "And where we want to go.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_297.wav": {
      "chunk_id": "298",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: is if we start seeing a pattern of things which are very consistent with a lot of other customers",
      "segments": [
        {
          "text": "is if we start seeing a pattern of things which are very consistent with a lot of other customers",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_298.wav": {
      "chunk_id": "299",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: and a lot of type of GPUs,\n[2025-06-01 19:13:26] Speaker 5: we will come back with recommendations\n[2025-06-01 19:13:28] Speaker 5: through an agentic AI type of app.",
      "segments": [
        {
          "text": "and a lot of type of GPUs,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "we will come back with recommendations",
          "timestamp": "2025-06-01 19:13:26",
          "speaker": "Speaker 5"
        },
        {
          "text": "through an agentic AI type of app.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_299.wav": {
      "chunk_id": "300",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: flow where probably just a reboot may fix the things or it could be specific to a driver.",
      "segments": [
        {
          "text": "flow where probably just a reboot may fix the things or it could be specific to a driver.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_300.wav": {
      "chunk_id": "301",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: the GPU driver you have, which has seen this incompatibility with the Mellanox drivers we have.",
      "segments": [
        {
          "text": "the GPU driver you have, which has seen this incompatibility with the Mellanox drivers we have.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_301.wav": {
      "chunk_id": "302",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: example. So we are trying to learn from using the data as well as all the issues customers.",
      "segments": [
        {
          "text": "example. So we are trying to learn from using the data as well as all the issues customers.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_302.wav": {
      "chunk_id": "303",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: give us to start recommending, right?\n[2025-06-01 19:13:27] Speaker 5: So this is just a start for us to start collecting,\n[2025-06-01 19:13:29] Speaker 5: but next approach for us is",
      "segments": [
        {
          "text": "give us to start recommending, right?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "So this is just a start for us to start collecting,",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        },
        {
          "text": "but next approach for us is",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_303.wav": {
      "chunk_id": "304",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: remove the noise and tell if there is really a issue with the host or if this is a transient issue.",
      "segments": [
        {
          "text": "remove the noise and tell if there is really a issue with the host or if this is a transient issue.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_304.wav": {
      "chunk_id": "305",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: or not an issue with something related to an experiment that has been set up.",
      "segments": [
        {
          "text": "or not an issue with something related to an experiment that has been set up.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_305.wav": {
      "chunk_id": "306",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: workload is being scheduled on this or the topology that it's been deployed with.\n[2025-06-01 19:13:29] Speaker 5: Any of those questions?",
      "segments": [
        {
          "text": "workload is being scheduled on this or the topology that it's been deployed with.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Any of those questions?",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_306.wav": {
      "chunk_id": "307",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Right, so that's where we want to get to.",
      "segments": [
        {
          "text": "Right, so that's where we want to get to.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_307.wav": {
      "chunk_id": "308",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Awesome. So here's the log as well.\n[2025-06-01 19:13:28] Speaker 5: This is this we'll build up more and more.",
      "segments": [
        {
          "text": "Awesome. So here's the log as well.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "This is this we'll build up more and more.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_308.wav": {
      "chunk_id": "309",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: stuff and it's all accessible either through portal or an api where you don't have to assess",
      "segments": [
        {
          "text": "stuff and it's all accessible either through portal or an api where you don't have to assess",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_309.wav": {
      "chunk_id": "310",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: an instance. Because the scripts are going to be standardized that what you see against",
      "segments": [
        {
          "text": "an instance. Because the scripts are going to be standardized that what you see against",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_310.wav": {
      "chunk_id": "311",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: what OCI support sees everything will be consistent and maybe in the future once we have support team",
      "segments": [
        {
          "text": "what OCI support sees everything will be consistent and maybe in the future once we have support team",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_311.wav": {
      "chunk_id": "312",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: running full diagnosis they know where to narrow down the issue to like exact GPU or the NICs or",
      "segments": [
        {
          "text": "running full diagnosis they know where to narrow down the issue to like exact GPU or the NICs or",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_312.wav": {
      "chunk_id": "313",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: anything instead of running this full you know six hours uh diagnosis on the host right",
      "segments": [
        {
          "text": "anything instead of running this full you know six hours uh diagnosis on the host right",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_313.wav": {
      "chunk_id": "314",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: So we're just trying to narrow down that time it takes to fix these machines too.\n[2025-06-01 19:13:30] Speaker 5: So that will help.",
      "segments": [
        {
          "text": "So we're just trying to narrow down that time it takes to fix these machines too.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "So that will help.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_314.wav": {
      "chunk_id": "315",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: When you say consistent, is the idea that you give us a set of scripts and we run these?",
      "segments": [
        {
          "text": "When you say consistent, is the idea that you give us a set of scripts and we run these?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_315.wav": {
      "chunk_id": "316",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: or they see the results of our health checks.",
      "segments": [
        {
          "text": "or they see the results of our health checks.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_316.wav": {
      "chunk_id": "317",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: So right now with the way it is integrated, the OCI support does not see the results, but you could just take...",
      "segments": [
        {
          "text": "So right now with the way it is integrated, the OCI support does not see the results, but you could just take...",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_317.wav": {
      "chunk_id": "318",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: these results copy paste in your support ticket if you need to OCI support will have access",
      "segments": [
        {
          "text": "these results copy paste in your support ticket if you need to OCI support will have access",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_318.wav": {
      "chunk_id": "319",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: the same health check tools and scripts that you are running.\n[2025-06-01 19:13:29] Speaker 5: So it's a consistent tool.",
      "segments": [
        {
          "text": "the same health check tools and scripts that you are running.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "So it's a consistent tool.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_319.wav": {
      "chunk_id": "320",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: that you both are running,\n[2025-06-01 19:13:26] Speaker 5: where what you have seen as the results,\n[2025-06-01 19:13:29] Speaker 5: for example, the score,",
      "segments": [
        {
          "text": "that you both are running,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "where what you have seen as the results,",
          "timestamp": "2025-06-01 19:13:26",
          "speaker": "Speaker 5"
        },
        {
          "text": "for example, the score,",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_320.wav": {
      "chunk_id": "321",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: So here's the flops, for example.\n[2025-06-01 19:13:28] Speaker 5: This is the duration, right?\n[2025-06-01 19:13:30] Speaker 5: What you are seeing...",
      "segments": [
        {
          "text": "So here's the flops, for example.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "This is the duration, right?",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        },
        {
          "text": "What you are seeing...",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_321.wav": {
      "chunk_id": "322",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: when OCI support is trying to run this on their own.\n[2025-06-01 19:13:28] Speaker 5: There is a lot of consistency.",
      "segments": [
        {
          "text": "when OCI support is trying to run this on their own.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "There is a lot of consistency.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_322.wav": {
      "chunk_id": "323",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Right. And if you see this GPU consistently coming back with like, okay, it takes 31 seconds.",
      "segments": [
        {
          "text": "Right. And if you see this GPU consistently coming back with like, okay, it takes 31 seconds.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_323.wav": {
      "chunk_id": "324",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: It's easy to narrow down saying that GQ7 is something.",
      "segments": [
        {
          "text": "It's easy to narrow down saying that GQ7 is something.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_324.wav": {
      "chunk_id": "325",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: that we need to request.",
      "segments": [
        {
          "text": "that we need to request.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_325.wav": {
      "chunk_id": "326",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: I see. Yeah, I think it would be even better if we can get to a stage where they...",
      "segments": [
        {
          "text": "I see. Yeah, I think it would be even better if we can get to a stage where they...",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_326.wav": {
      "chunk_id": "327",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: like have access to historical results and they can just see things that are\n[2025-06-01 19:13:28] Speaker 1: ZeeBrand.",
      "segments": [
        {
          "text": "like have access to historical results and they can just see things that are",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "ZeeBrand.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_327.wav": {
      "chunk_id": "328",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: Yeah.",
      "segments": [
        {
          "text": "Yeah.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_328.wav": {
      "chunk_id": "329",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: instead of having to reproduce and copy pasting things.",
      "segments": [
        {
          "text": "instead of having to reproduce and copy pasting things.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_329.wav": {
      "chunk_id": "330",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: i fully agree i think that's our goal but we are not a oci service yet",
      "segments": [
        {
          "text": "i fully agree i think that's our goal but we are not a oci service yet",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_330.wav": {
      "chunk_id": "331",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: right and uh because it's all running the customer's tenancy uh there's obviously",
      "segments": [
        {
          "text": "right and uh because it's all running the customer's tenancy uh there's obviously",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_331.wav": {
      "chunk_id": "332",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: little bit of things about what we can collect, what we cannot. And we had to go through those.",
      "segments": [
        {
          "text": "little bit of things about what we can collect, what we cannot. And we had to go through those.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_332.wav": {
      "chunk_id": "333",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: product approval phases.\n[2025-06-01 19:13:28] Speaker 5: And then we will probably\n[2025-06-01 19:13:29] Speaker 5: support and have access to this.",
      "segments": [
        {
          "text": "product approval phases.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "And then we will probably",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        },
        {
          "text": "support and have access to this.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_333.wav": {
      "chunk_id": "334",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: Okay, makes sense. One other question for Prometheus. You mentioned at some point in the",
      "segments": [
        {
          "text": "Okay, makes sense. One other question for Prometheus. You mentioned at some point in the",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_334.wav": {
      "chunk_id": "335",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: this slide something about setting up a CPU cluster or gate cluster to run Prometheus.",
      "segments": [
        {
          "text": "this slide something about setting up a CPU cluster or gate cluster to run Prometheus.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_335.wav": {
      "chunk_id": "336",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: can we reuse our existing primukes instead?",
      "segments": [
        {
          "text": "can we reuse our existing primukes instead?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_336.wav": {
      "chunk_id": "337",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Yes, yes, absolutely. You can use your existing. You need to just enable push gateway and add.",
      "segments": [
        {
          "text": "Yes, yes, absolutely. You can use your existing. You need to just enable push gateway and add.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_337.wav": {
      "chunk_id": "338",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: push gateway configurations because that's how all of the scripts push their results and metrics.",
      "segments": [
        {
          "text": "push gateway configurations because that's how all of the scripts push their results and metrics.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_338.wav": {
      "chunk_id": "339",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Okay, can you give a bit more detail about how this works?",
      "segments": [
        {
          "text": "Okay, can you give a bit more detail about how this works?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_339.wav": {
      "chunk_id": "340",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: scripts push metrics or how does that work",
      "segments": [
        {
          "text": "scripts push metrics or how does that work",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_340.wav": {
      "chunk_id": "341",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Yeah, Hrithika, can you elaborate on this?",
      "segments": [
        {
          "text": "Yeah, Hrithika, can you elaborate on this?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_342.wav": {
      "chunk_id": "343",
      "transcript": "[2025-06-01 19:13:25] Speaker 2: Hello? Can you hear me?",
      "segments": [
        {
          "text": "Hello? Can you hear me?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 2"
        }
      ],
      "language": "en"
    },
    "chunk_341.wav": {
      "chunk_id": "342",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Is VTK wrong?",
      "segments": [
        {
          "text": "Is VTK wrong?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_343.wav": {
      "chunk_id": "344",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Yeah.",
      "segments": [
        {
          "text": "Yeah.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_344.wav": {
      "chunk_id": "345",
      "transcript": "[2025-06-01 19:13:25] Speaker 2: All right. Could you give that question once again?",
      "segments": [
        {
          "text": "All right. Could you give that question once again?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 2"
        }
      ],
      "language": "en"
    },
    "chunk_345.wav": {
      "chunk_id": "346",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: It was just having a bit more detail about how the metrics get emitted.",
      "segments": [
        {
          "text": "It was just having a bit more detail about how the metrics get emitted.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_346.wav": {
      "chunk_id": "347",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: Because I understand there are scripts and then I'm just trying to figure out like how we could.",
      "segments": [
        {
          "text": "Because I understand there are scripts and then I'm just trying to figure out like how we could.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_347.wav": {
      "chunk_id": "348",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: scrape our own metrics.",
      "segments": [
        {
          "text": "scrape our own metrics.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_348.wav": {
      "chunk_id": "349",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: Oh yeah, so we basically build the node exporter, DCGM, AMD exporter, all of that depending on the GPU.",
      "segments": [
        {
          "text": "Oh yeah, so we basically build the node exporter, DCGM, AMD exporter, all of that depending on the GPU.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_349.wav": {
      "chunk_id": "350",
      "transcript": "[2025-06-01 19:13:25] Speaker 2: it is and bring those up and there are also some metrics which are OCI specific which are",
      "segments": [
        {
          "text": "it is and bring those up and there are also some metrics which are OCI specific which are",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 2"
        }
      ],
      "language": "en"
    },
    "chunk_350.wav": {
      "chunk_id": "351",
      "transcript": "[2025-06-01 19:13:25] Speaker 2: return in a Go plugin and that plugin\n[2025-06-01 19:13:29] Speaker 2: fits metrics to the push gateway at a regular interval.",
      "segments": [
        {
          "text": "return in a Go plugin and that plugin",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 2"
        },
        {
          "text": "fits metrics to the push gateway at a regular interval.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 2"
        }
      ],
      "language": "en"
    },
    "chunk_351.wav": {
      "chunk_id": "352",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Yeah, all of the scripts here are...\n[2025-06-01 19:13:27] Speaker 5: Does that make sense?",
      "segments": [
        {
          "text": "Yeah, all of the scripts here are...",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Does that make sense?",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_352.wav": {
      "chunk_id": "353",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: push gateway if you see it here and",
      "segments": [
        {
          "text": "push gateway if you see it here and",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_353.wav": {
      "chunk_id": "354",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: And these are scraped by Prometheus\n[2025-06-01 19:13:27] Speaker 5: based on Prometheus script config.\n[2025-06-01 19:13:29] Speaker 5: And-",
      "segments": [
        {
          "text": "And these are scraped by Prometheus",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "based on Prometheus script config.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        },
        {
          "text": "And-",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_354.wav": {
      "chunk_id": "355",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Push gateway is part of a service that is default in Prometheus server install.\n[2025-06-01 19:13:30] Speaker 5: And it's the same.",
      "segments": [
        {
          "text": "Push gateway is part of a service that is default in Prometheus server install.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "And it's the same.",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_355.wav": {
      "chunk_id": "356",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: mechanism.\n[2025-06-01 19:13:27] Speaker 5: Gotcha.\n[2025-06-01 19:13:28] Speaker 1: Okay.\n[2025-06-01 19:13:28] Speaker 1: I'll look into this a bit more.\n[2025-06-01 19:13:29] Speaker 1: I haven't used push gateway before.",
      "segments": [
        {
          "text": "mechanism.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Gotcha.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        },
        {
          "text": "Okay.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 1"
        },
        {
          "text": "I'll look into this a bit more.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 1"
        },
        {
          "text": "I haven't used push gateway before.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_356.wav": {
      "chunk_id": "357",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: So that's probably where my gap comes from.\n[2025-06-01 19:13:27] Speaker 1: Okay.\n[2025-06-01 19:13:27] Speaker 5: Yeah, I think it's part of the setup.",
      "segments": [
        {
          "text": "So that's probably where my gap comes from.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "Okay.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 1"
        },
        {
          "text": "Yeah, I think it's part of the setup.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_357.wav": {
      "chunk_id": "358",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: And if you go, if you run Prometheus through operator,\n[2025-06-01 19:13:28] Speaker 5: Push Gateway is usually installed as a service.",
      "segments": [
        {
          "text": "And if you go, if you run Prometheus through operator,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Push Gateway is usually installed as a service.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_358.wav": {
      "chunk_id": "359",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: It should have its own service endpoint,\n[2025-06-01 19:13:28] Speaker 5: and you have to just enable a few things.",
      "segments": [
        {
          "text": "It should have its own service endpoint,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "and you have to just enable a few things.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_359.wav": {
      "chunk_id": "360",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: and you're good to go. Yeah. So, this is for instead of you going and reaching out.",
      "segments": [
        {
          "text": "and you're good to go. Yeah. So, this is for instead of you going and reaching out.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_360.wav": {
      "chunk_id": "361",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: going and reaching out and pulling the metrics out which is where you need firewall exception",
      "segments": [
        {
          "text": "going and reaching out and pulling the metrics out which is where you need firewall exception",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_361.wav": {
      "chunk_id": "362",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: and opening the ports and all of that.\n[2025-06-01 19:13:27] Speaker 5: Here, any metrics you are generating, including DCGM,",
      "segments": [
        {
          "text": "and opening the ports and all of that.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Here, any metrics you are generating, including DCGM,",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_362.wav": {
      "chunk_id": "363",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: all of those are pool metrics, right?\n[2025-06-01 19:13:27] Speaker 5: We push it directly to the push page.",
      "segments": [
        {
          "text": "all of those are pool metrics, right?",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "We push it directly to the push page.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_363.wav": {
      "chunk_id": "364",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: and your Prometheus is scraping push gateway basically.\n[2025-06-01 19:13:29] Speaker 5: It's like an intermediate data store.",
      "segments": [
        {
          "text": "and your Prometheus is scraping push gateway basically.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "It's like an intermediate data store.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_364.wav": {
      "chunk_id": "365",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: All right. Any further questions? And we are also eager if you have any feedback.",
      "segments": [
        {
          "text": "All right. Any further questions? And we are also eager if you have any feedback.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_365.wav": {
      "chunk_id": "366",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: can think about we are thinking in next roughly two weeks you can you can have access to all of",
      "segments": [
        {
          "text": "can think about we are thinking in next roughly two weeks you can you can have access to all of",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_366.wav": {
      "chunk_id": "367",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: the health check scripts.\n[2025-06-01 19:13:27] Speaker 5: We'll get access to your repo\n[2025-06-01 19:13:29] Speaker 5: once you share your GitHub IDs.",
      "segments": [
        {
          "text": "the health check scripts.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "We'll get access to your repo",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        },
        {
          "text": "once you share your GitHub IDs.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_367.wav": {
      "chunk_id": "368",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: can poke around and really we are here to listen and and build something that that makes uh",
      "segments": [
        {
          "text": "can poke around and really we are here to listen and and build something that that makes uh",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_368.wav": {
      "chunk_id": "369",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: life easy right so we are here to listen and you know continue to iterate as fast as we",
      "segments": [
        {
          "text": "life easy right so we are here to listen and you know continue to iterate as fast as we",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_369.wav": {
      "chunk_id": "370",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: can to give you what you're looking for.\n[2025-06-01 19:13:27] Speaker 5: So.\n[2025-06-01 19:13:28] Speaker 1: Thanks, Samar.\n[2025-06-01 19:13:29] Speaker 1: I think overall this is, you know.",
      "segments": [
        {
          "text": "can to give you what you're looking for.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "So.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        },
        {
          "text": "Thanks, Samar.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 1"
        },
        {
          "text": "I think overall this is, you know.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_370.wav": {
      "chunk_id": "371",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: something that we've been asking for. So really, really happy it's, it's getting there.",
      "segments": [
        {
          "text": "something that we've been asking for. So really, really happy it's, it's getting there.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_371.wav": {
      "chunk_id": "372",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: and you all are focusing your efforts there.\n[2025-06-01 19:13:26] Speaker 1: It's definitely heading the right direction.",
      "segments": [
        {
          "text": "and you all are focusing your efforts there.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "It's definitely heading the right direction.",
          "timestamp": "2025-06-01 19:13:26",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_372.wav": {
      "chunk_id": "373",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: I think looking at what we have today that we built ourselves a best over the past year,\n[2025-06-01 19:13:29] Speaker 1: it's definitely...",
      "segments": [
        {
          "text": "I think looking at what we have today that we built ourselves a best over the past year,",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "it's definitely...",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_373.wav": {
      "chunk_id": "374",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: not there yet. I think what we have right now is a bit more advanced just because we've built",
      "segments": [
        {
          "text": "not there yet. I think what we have right now is a bit more advanced just because we've built",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_374.wav": {
      "chunk_id": "375",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: our own set of scripts and like we've iterated on them and we have all that automation.",
      "segments": [
        {
          "text": "our own set of scripts and like we've iterated on them and we have all that automation.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_375.wav": {
      "chunk_id": "376",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: and integration with Kubernetes already.\n[2025-06-01 19:13:27] Speaker 1: But I like where this is going and yeah, excited too.",
      "segments": [
        {
          "text": "and integration with Kubernetes already.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "But I like where this is going and yeah, excited too.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_376.wav": {
      "chunk_id": "377",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: work with you all too.\n[2025-06-01 19:13:26] Speaker 1: It's great.\n[2025-06-01 19:13:27] Speaker 5: Okay.\n[2025-06-01 19:13:28] Speaker 5: Yeah.\n[2025-06-01 19:13:28] Speaker 5: We'll try to,\n[2025-06-01 19:13:30] Speaker 5: right now,\n[2025-06-01 19:13:31] Speaker 5: we are not overly",
      "segments": [
        {
          "text": "work with you all too.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "It's great.",
          "timestamp": "2025-06-01 19:13:26",
          "speaker": "Speaker 1"
        },
        {
          "text": "Okay.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        },
        {
          "text": "Yeah.",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        },
        {
          "text": "We'll try to,",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        },
        {
          "text": "right now,",
          "timestamp": "2025-06-01 19:13:30",
          "speaker": "Speaker 5"
        },
        {
          "text": "we are not overly",
          "timestamp": "2025-06-01 19:13:31",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_377.wav": {
      "chunk_id": "378",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: Kubernetes heavy features and if we will probably in the next iteration or a milestone",
      "segments": [
        {
          "text": "Kubernetes heavy features and if we will probably in the next iteration or a milestone",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_378.wav": {
      "chunk_id": "379",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: add all of those capabilities to bring Kubernetes metrics and that experience together.",
      "segments": [
        {
          "text": "add all of those capabilities to bring Kubernetes metrics and that experience together.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_379.wav": {
      "chunk_id": "380",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: And hopefully, Sisal, I'll post that.\n[2025-06-01 19:13:27] Speaker 5: You would be open to trying it out and giving us the feedback.",
      "segments": [
        {
          "text": "And hopefully, Sisal, I'll post that.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "You would be open to trying it out and giving us the feedback.",
          "timestamp": "2025-06-01 19:13:27",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_380.wav": {
      "chunk_id": "381",
      "transcript": "[2025-06-01 19:13:25] Speaker 5: and iterating like that.\n[2025-06-01 19:13:29] Speaker 1: Sounds good.\n[2025-06-01 19:13:32] Speaker 5: Thanks for making the time to give us a demo.",
      "segments": [
        {
          "text": "and iterating like that.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "Sounds good.",
          "timestamp": "2025-06-01 19:13:29",
          "speaker": "Speaker 1"
        },
        {
          "text": "Thanks for making the time to give us a demo.",
          "timestamp": "2025-06-01 19:13:32",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_381.wav": {
      "chunk_id": "382",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: Appreciate it.\n[2025-06-01 19:13:25] Speaker 5: Thanks for spending your time with us as well.\n[2025-06-01 19:13:28] Speaker 5: So anyone else, any questions?",
      "segments": [
        {
          "text": "Appreciate it.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        },
        {
          "text": "Thanks for spending your time with us as well.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 5"
        },
        {
          "text": "So anyone else, any questions?",
          "timestamp": "2025-06-01 19:13:28",
          "speaker": "Speaker 5"
        }
      ],
      "language": "en"
    },
    "chunk_382.wav": {
      "chunk_id": "383",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: Thank you.",
      "segments": [
        {
          "text": "Thank you.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_383.wav": {
      "chunk_id": "384",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: Thank you.",
      "segments": [
        {
          "text": "Thank you.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_384.wav": {
      "chunk_id": "385",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: Thank you.",
      "segments": [
        {
          "text": "Thank you.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    },
    "chunk_385.wav": {
      "chunk_id": "386",
      "transcript": "[2025-06-01 19:13:25] Speaker 1: Thank you.",
      "segments": [
        {
          "text": "Thank you.",
          "timestamp": "2025-06-01 19:13:25",
          "speaker": "Speaker 1"
        }
      ],
      "language": "en"
    }
  },
  "transcript": "[2025-06-01 19:13:25] Speaker 5: All right. Thank you all. Morning, afternoon. So my name is Amar Gowda. I am one of the\n[2025-06-01 19:13:30] Speaker 5: products.\n[2025-06-01 19:13:25] Speaker 5: managers leading the OCI Lens initiative. So right now it's kind of what we call incubation.\n[2025-06-01 19:13:25] Speaker 5: phases so we are not yet to be a mvp or closer to it so we're kind of getting early feedback\n[2025-06-01 19:13:25] Speaker 5: and this is like think of this as a kind of private preview in a way right so a little earlier on\n[2025-06-01 19:13:25] Speaker 5: on the journey.\n[2025-06-01 19:13:26] Speaker 5: But this is something we started looking into,\n[2025-06-01 19:13:31] Speaker 5: which we, I think we spoke with.\n[2025-06-01 19:13:25] Speaker 5: you, Cecil, you and the rest of the team on what does it take to operate at scale?\n[2025-06-01 19:13:25] Speaker 5: what are the things that we could improve on, especially the monitoring, the health check.\n[2025-06-01 19:13:25] Speaker 5: side of the things, which has, you know, you gave a set of requirements and that led us.\n[2025-06-01 19:13:25] Speaker 5: to building something to help customers like you.\n[2025-06-01 19:13:30] Speaker 5: Okay, so I have a team here.\n[2025-06-01 19:13:32] Speaker 5: Joletta is...\n[2025-06-01 19:13:25] Speaker 5: another software engineers somia on the call is our data scientist selection ml engineer\n[2025-06-01 19:13:30] Speaker 5: uh\n[2025-06-01 19:13:25] Speaker 5: also have uh hithika who's our golang developer she's ex uh akis team so that's where if you all can\n[2025-06-01 19:13:25] Speaker 5: connect a little bit too.\n[2025-06-01 19:13:27] Speaker 5: All right. Today, I'm going to keep it more focused on the demo.\n[2025-06-01 19:13:25] Speaker 5: and what this tool is all about.\n[2025-06-01 19:13:27] Speaker 5: And then we'll, you know, answer questions\n[2025-06-01 19:13:29] Speaker 5: and kind of talk through.\n[2025-06-01 19:13:25] Speaker 5: But most importantly, we want to hear if the current version has a set of features you're\n[2025-06-01 19:13:25] Speaker 5: looking for? Is it missing? Is it you want to see something more? Because we are kind of very\n[2025-06-01 19:13:25] Speaker 5: rapidly on a weekly sprint uh releasing the features to this and we are really happy to incorporate\n[2025-06-01 19:13:25] Speaker 5: anything and work on how you can onboard to this by the way\n[2025-06-01 19:13:31] Speaker 5: uh so four areas where we are focused on\n[2025-06-01 19:13:25] Speaker 5: this solution is continuous GPU and cluster level monitoring of both NVIDIA GPUs and AMD GPUs.\n[2025-06-01 19:13:25] Speaker 5: together, right? So this is how we want to kind of platform\n[2025-06-01 19:13:29] Speaker 5: agnostic solution that works for all GPUs.\n[2025-06-01 19:13:25] Speaker 5: and has all the latest metrics available for you to digest and look at.\n[2025-06-01 19:13:32] Speaker 5: The next thing which we've highlighted...\n[2025-06-01 19:13:25] Speaker 5: focused on is the health checks piece to this right are my nodes healthy are they performing to\n[2025-06-01 19:13:30] Speaker 5: what they\n[2025-06-01 19:13:25] Speaker 5: should be uh active health checks active monitoring is is is a huge investment that we did uh and i'll\n[2025-06-01 19:13:32] Speaker 5: go over some\n[2025-06-01 19:13:25] Speaker 5: details about what all health checks that we have enabled including the RDMA cluster level.\n[2025-06-01 19:13:25] Speaker 5: checks that we call MPI tests as part of the solution fully baked into.\n[2025-06-01 19:13:30] Speaker 5: We kept it to cloud native.\n[2025-06-01 19:13:25] Speaker 5: because I heard it very clear that it has to be Grafana, Prometheus, Native, or Otel, anything open source.\n[2025-06-01 19:13:25] Speaker 5: Cloud Native Alliance so that it's easy to be move between clouds or on-prem and use\n[2025-06-01 19:13:29] Speaker 5: the same existing.\n[2025-06-01 19:13:25] Speaker 5: tools you always used for for monitoring another area that we've paid attention and we built is the\n[2025-06-01 19:13:25] Speaker 5: team level tracking. A lot of these large size clusters are usually used by multiple teams and\n[2025-06-01 19:13:25] Speaker 5: everybody wants to know the health of their own subset of systems or how their experiment is\n[2025-06-01 19:13:30] Speaker 5: performing.\n[2025-06-01 19:13:25] Speaker 5: if they have an unhealthy node, all of those combinations.\n[2025-06-01 19:13:29] Speaker 5: And another important thing is about\n[2025-06-01 19:13:25] Speaker 5: cost tracking right people want to see how much computer resources they've used uh whatever the\n[2025-06-01 19:13:25] Speaker 5: the power the total gpu power they have used for running this experiment right those were a few\n[2025-06-01 19:13:29] Speaker 5: things that\n[2025-06-01 19:13:25] Speaker 5: that we also focused to build on this.\n[2025-06-01 19:13:29] Speaker 5: The current set of features that we have\n[2025-06-01 19:13:32] Speaker 5: and what we have built right now\n[2025-06-01 19:13:25] Speaker 5: now is first thing tenancy level monitoring you no longer have region barriers right so we any\n[2025-06-01 19:13:25] Speaker 5: data, any region, OCI region you may be in, everything is monitorable as a single instance\n[2025-06-01 19:13:31] Speaker 5: for us.\n[2025-06-01 19:13:25] Speaker 5: So I'm going to show you a demo.\n[2025-06-01 19:13:27] Speaker 5: We allow you to monitor either single, bare metal, virtual machine\n[2025-06-01 19:13:25] Speaker 5: instances or a full oke cluster or an hpc cluster that if you may be using slurm or a native uh\n[2025-06-01 19:13:25] Speaker 5: called cluster network, compute cluster setup in OCI.\n[2025-06-01 19:13:29] Speaker 5: The third part of the feature that we worked on\n[2025-06-01 19:13:25] Speaker 5: and all of this we're going to see a demo quickly but i'm going to just spend maybe five more minutes\n[2025-06-01 19:13:25] Speaker 5: and then go to the demo.\n[2025-06-01 19:13:26] Speaker 5: Is it team level tracking?\n[2025-06-01 19:13:27] Speaker 5: You can create team level tracking.\n[2025-06-01 19:13:25] Speaker 5: handpicking whichever nodes are part of this experiment.\n[2025-06-01 19:13:29] Speaker 5: We are also working towards...\n[2025-06-01 19:13:25] Speaker 5: automatically fetching the nodes that are running experiment based on Kubernetes\n[2025-06-01 19:13:29] Speaker 5: how the job system.\n[2025-06-01 19:13:25] Speaker 5: scheduled. So that's another area we're working on automatically, dynamically pulling the nodes that\n[2025-06-01 19:13:25] Speaker 5: part of that experiment rather than you allocating what compute nodes go to.\n[2025-06-01 19:13:31] Speaker 5: This I've already said.\n[2025-06-01 19:13:25] Speaker 5: already have both of them running and i'm going to show you that uh the difference between what we do\n[2025-06-01 19:13:25] Speaker 5: with performance monitoring and health check is we go very close to the layers that an ML engineer would\n[2025-06-01 19:13:25] Speaker 5: operate under, which is PyTorch for us, PyTorch and JAX primarily, right? So we picked up PyTorch base.\n[2025-06-01 19:13:25] Speaker 5: matmal and linear regression based performance testing to achieve how many flops did we achieve\n[2025-06-01 19:13:25] Speaker 5: on this compute node how much is each gpu performing and is it is it within the threshold of\n[2025-06-01 19:13:25] Speaker 5: the specification from NVIDIA or AMD what we have traditionally seen. So we have a baseline.\n[2025-06-01 19:13:25] Speaker 5: that we score the performance to because it's the standard set of precision based testing either FBA.\n[2025-06-01 19:13:25] Speaker 5: FP16, FP32, it automatically does all of this. And most of this code, by the way, for the health\n[2025-06-01 19:13:25] Speaker 5: will all be open source so you can see you can change the things if you like or add to it\n[2025-06-01 19:13:25] Speaker 5: right and please feel free to contribute to it too.\n[2025-06-01 19:13:28] Speaker 5: This you've seen it.\n[2025-06-01 19:13:30] Speaker 5: The approach we have taken.\n[2025-06-01 19:13:25] Speaker 5: here is instead of asking you to poke holes in your existing cluster or networks, we basically push the\n[2025-06-01 19:13:25] Speaker 5: metrics and we push the health check data to the Prometheus and our central control plane.\n[2025-06-01 19:13:25] Speaker 5: It could be looked at as, oh, I need to open this port, that port, no exception.\n[2025-06-01 19:13:25] Speaker 5: if you're in a vc and in a production environment where everything is locked down egress is usually\n[2025-06-01 19:13:25] Speaker 5: easier and you can always sniff the egress but these are all running within your own tenancy so\n[2025-06-01 19:13:25] Speaker 5: So the origination of all of the metrics to where it's being sent is all within your network.\n[2025-06-01 19:13:25] Speaker 5: nothing is going into the public. All right. So I'm going to go over this.\n[2025-06-01 19:13:25] Speaker 5: but there are plenty of metrics, just a lot.\n[2025-06-01 19:13:28] Speaker 5: And it's kind of an eye candy chart on Grafana's to look.\n[2025-06-01 19:13:25] Speaker 5: at but i think you get the point right you have full nvidia dcgm exporter all metrics\n[2025-06-01 19:13:25] Speaker 5: You have all AMD SMI metrics.\n[2025-06-01 19:13:27] Speaker 5: You have all of the RDMA metrics that is particularly on our ROC.\n[2025-06-01 19:13:25] Speaker 5: implementation that we sniffed the melanocs drivers for to capture that front end next\n[2025-06-01 19:13:25] Speaker 5: node health is included, health check, full check is included,\n[2025-06-01 19:13:29] Speaker 5: and the traditional disk IO usage.\n[2025-06-01 19:13:25] Speaker 5: all of those that you usually get with Prometheus already included.\n[2025-06-01 19:13:28] Speaker 5: So all of these is bundled as one.\n[2025-06-01 19:13:25] Speaker 5: unpacking.\n[2025-06-01 19:13:25] Speaker 5: On the health checks piece, these are all the tests we do today and we'll continue to add more or adjust.\n[2025-06-01 19:13:25] Speaker 5: based on how performance we see we do extensive benchmarking to see where the threshold should\n[2025-06-01 19:13:25] Speaker 5: be or the baseline should be and then we either go up and down based on how we are seeing.\n[2025-06-01 19:13:25] Speaker 5: example the what should be the ideal mfu on a 140 gb against b200 or mi300x right and then we we lower it\n[2025-06-01 19:13:25] Speaker 5: if needed right so but we work with our vendors to also see if this we already doing the right way or not\n[2025-06-01 19:13:25] Speaker 5: So here are all the checks we run.\n[2025-06-01 19:13:27] Speaker 5: And all of these, once they complete, you will see a...\n[2025-06-01 19:13:25] Speaker 5: metrics flowing through Grafana and you'll also see this.\n[2025-06-01 19:13:25] Speaker 5: Very simple. This is how the architecture is. I'm not going to spend too much time here either.\n[2025-06-01 19:13:25] Speaker 5: because we are evolving how this is going to go right now the way we will release it is this will\n[2025-06-01 19:13:25] Speaker 5: deploy as a we're not a kubernetes operator yet but you have to basically deploy a dedicated\n[2025-06-01 19:13:25] Speaker 5: OKE cluster with just CPU nodes, which installs Prometheus Grafana open source and our control.\n[2025-06-01 19:13:25] Speaker 5: plane api as well as portal right those are all the components that come as part of this\n[2025-06-01 19:13:25] Speaker 5: And this is that footprint.\n[2025-06-01 19:13:27] Speaker 5: We run a local Postgres for Profana storage.\n[2025-06-01 19:13:30] Speaker 5: We also use Postgres for...\n[2025-06-01 19:13:25] Speaker 5: kind of operating these things.\n[2025-06-01 19:13:27] Speaker 5: This is our kind of MVP minus one approach, right?\n[2025-06-01 19:13:32] Speaker 5: And once this...\n[2025-06-01 19:13:25] Speaker 5: becomes a service this will start looking differently any questions so far\n[2025-06-01 19:13:25] Speaker 1: I have a few questions.\n[2025-06-01 19:13:26] Speaker 1: Do you prefer we wait till the end?\n[2025-06-01 19:13:25] Speaker 5: Yeah, let's take it, Zizal.\n[2025-06-01 19:13:26] Speaker 5: Or if you want to see the demo and then ask those questions, it's up to you.\n[2025-06-01 19:13:25] Speaker 1: I guess let's do the demo and then we can come back to questions.\n[2025-06-01 19:13:28] Speaker 1: Maybe that will answer some of it.\n[2025-06-01 19:13:25] Speaker 1: questions perfect yep all right so the the way we we know you can install this is we you will\n[2025-06-01 19:13:25] Speaker 5: have a GitHub repo where it could go and say deploy this and it sets up a Kubernetes cluster.\n[2025-06-01 19:13:25] Speaker 5: Kubernetes cluster setup and all of the Grafana Prometeas,\n[2025-06-01 19:13:29] Speaker 5: everything is installed.\n[2025-06-01 19:13:25] Speaker 5: in your primary OSID or your tenancy region,\n[2025-06-01 19:13:29] Speaker 5: you will get access to a portal like this.\n[2025-06-01 19:13:25] Speaker 5: right we call it corino lens but it is basically the lens so once you are here\n[2025-06-01 19:13:25] Speaker 5: right it will go it has the ability to do a multi-region query in a single api\n[2025-06-01 19:13:25] Speaker 5: So everything is API first, you have portal and there is a REST API endpoint you can interact.\n[2025-06-01 19:13:25] Speaker 5: all of that is deployed in your tenancy so you can lock it down if you like to\n[2025-06-01 19:13:25] Speaker 5: Right now we run on a public domain just for a demo, but everything in here.\n[2025-06-01 19:13:30] Speaker 5: So if you see here.\n[2025-06-01 19:13:25] Speaker 5: This is done. If I refresh this page, it's going to come back with\n[2025-06-01 19:13:25] Speaker 5: It's doing all the regions that you have subscribed in your OSIT or Oracle tenancy.\n[2025-06-01 19:13:25] Speaker 5: Then it comes back and tells you, here are all the instances that I can monitor.\n[2025-06-01 19:13:28] Speaker 5: These are basically...\n[2025-06-01 19:13:25] Speaker 5: just GPU instances that are running okay if you have new instances running you can also add\n[2025-06-01 19:13:25] Speaker 5: what we call kind of plug-in.\n[2025-06-01 19:13:27] Speaker 5: So it's a plug-in model.\n[2025-06-01 19:13:28] Speaker 5: You already say, okay, start monitoring.\n[2025-06-01 19:13:25] Speaker 5: these to OCI lengths. And so if you look at here, I have Frankfurt and Ashburn machines showing.\n[2025-06-01 19:13:25] Speaker 5: up and it allows me to combine all of this and say they're all part of the same team or same\n[2025-06-01 19:13:25] Speaker 5: experiment or same way i want to monitor and i can create what's called monitoring right\n[2025-06-01 19:13:25] Speaker 5: So before I go there, right, how can you start monitoring this?\n[2025-06-01 19:13:29] Speaker 5: If you have an existing instance...\n[2025-06-01 19:13:25] Speaker 5: running or a new instance being provisioned you have to just include this script for now right\n[2025-06-01 19:13:25] Speaker 5: we will we will change the way it is we're going to make it a native oci plugin\n[2025-06-01 19:13:25] Speaker 5: once we upstream all of this to our plugin framework.\n[2025-06-01 19:13:27] Speaker 5: But for now, it's basically a tarz file.\n[2025-06-01 19:13:25] Speaker 5: and it's a Golang-based code primarily.\n[2025-06-01 19:13:28] Speaker 5: The health checks are all Python-based.\n[2025-06-01 19:13:25] Speaker 5: And this is basically end of the day, just all these metrics are composed and pushed.\n[2025-06-01 19:13:25] Speaker 5: through Prometheus Push gateway,\n[2025-06-01 19:13:27] Speaker 5: which is getting scraped by Push.\n[2025-06-01 19:13:28] Speaker 5: So architecture.\n[2025-06-01 19:13:25] Speaker 5: this is nothing very different or rocket science here right so it's very simple\n[2025-06-01 19:13:25] Speaker 5: straightforward, but what it runs and how it runs is what the value we are adding.\n[2025-06-01 19:13:25] Speaker 5: This is like a cloud in its script as well.\n[2025-06-01 19:13:27] Speaker 5: You can add it as part of a new provisioning.\n[2025-06-01 19:13:25] Speaker 5: instance automatically every new instance that comes up has monitoring enabled and everything is\n[2025-06-01 19:13:25] Speaker 5: running at the host level as a system service it's not operating at the kubernetes layers or at the\n[2025-06-01 19:13:25] Speaker 5: the Slurm application layers.\n[2025-06-01 19:13:27] Speaker 5: It's running directly on the bare metal host.\n[2025-06-01 19:13:30] Speaker 5: And we felt that was.\n[2025-06-01 19:13:25] Speaker 5: the ideal way and the right place for us to remove specific implementations to Kubernetes.\n[2025-06-01 19:13:25] Speaker 5: or Slurm or others.\n[2025-06-01 19:13:28] Speaker 5: So we can also scan Kubernetes clusters you have running\n[2025-06-01 19:13:31] Speaker 5: or you have RDMA.\n[2025-06-01 19:13:25] Speaker 5: cluster networks or what we call compute clusters and allow you to also monitor that.\n[2025-06-01 19:13:25] Speaker 5: And when you check the whole Kubernetes cluster, all the GPU nodes under it are automatically\n[2025-06-01 19:13:30] Speaker 5: scanned.\n[2025-06-01 19:13:25] Speaker 5: and add it to the monitoring for us.\n[2025-06-01 19:13:27] Speaker 5: That's the experience.\n[2025-06-01 19:13:30] Speaker 5: Okay.\n[2025-06-01 19:13:30] Speaker 5: So I'll quickly show you how...\n[2025-06-01 19:13:25] Speaker 5: you know this this is basically a bare minimum um portal uh access we have everything is api\n[2025-06-01 19:13:25] Speaker 5: first so you get exactly what you're doing here you could you could do that uh through\n[2025-06-01 19:13:25] Speaker 5: REST API endpoints. So once this loads up, because it's doing like a close to 10 region query,\n[2025-06-01 19:13:25] Speaker 5: takes roughly six seconds but six to ten seconds we will we'll make it better with some cash\n[2025-06-01 19:13:25] Speaker 5: So, yeah, no, we have close to 30, 30 plus machines, right, Joleta?\n[2025-06-01 19:13:33] Speaker 5: I think it's performing.\n[2025-06-01 19:13:25] Speaker 5: okay but you know joletta is working hard to see how she can do parallel um parallelization\n[2025-06-01 19:13:25] Speaker 5: of some of these runs and get back.\n[2025-06-01 19:13:27] Speaker 5: But we got them better.\n[2025-06-01 19:13:29] Speaker 5: We started from 30 seconds.\n[2025-06-01 19:13:25] Speaker 5: by now at six seconds, but we'll keep pushing.\n[2025-06-01 19:13:29] Speaker 5: All right. So it allows me to create a...\n[2025-06-01 19:13:25] Speaker 5: monitoring ring, it's like just an arbitrary way for you to\n[2025-06-01 19:13:28] Speaker 5: combine these resources and say\n[2025-06-01 19:13:25] Speaker 5: I want a dedicated dashboard for this,\n[2025-06-01 19:13:27] Speaker 5: these set of machines, right?\n[2025-06-01 19:13:29] Speaker 5: That's what you.\n[2025-06-01 19:13:25] Speaker 5: allows you to create a ring and if you go to monitoring rings here and you have OK,\n[2025-06-01 19:13:30] Speaker 5: this is.\n[2025-06-01 19:13:25] Speaker 5: for ML training, this is for the team, this is for cost center, whatever, however you\n[2025-06-01 19:13:25] Speaker 5: want to use this for kind of bundling all the things. Right? And the thing about\n[2025-06-01 19:13:25] Speaker 5: this is you can always come back and add more instances or remove the instances if they go\n[2025-06-01 19:13:25] Speaker 5: offline or you have to turn back in whatever right so so every every ring you create monitor\n[2025-06-01 19:13:25] Speaker 5: ring you create comes with a dedicated Grafana board which includes all the hosts that are\n[2025-06-01 19:13:25] Speaker 5: part of this and I'm going to click you through the Grafana.\n[2025-06-01 19:13:31] Speaker 5: So what you see here at the first part of\n[2025-06-01 19:13:25] Speaker 5: this is the health summary of all the compute nodes that are part of this, right? So we added more nodes.\n[2025-06-01 19:13:25] Speaker 5: which you're in this part just to show you demo, right?\n[2025-06-01 19:13:27] Speaker 5: So if you see the first board here is this is the.\n[2025-06-01 19:13:25] Speaker 5: actual health check of all the performance related checks that we did on the host when you activate\n[2025-06-01 19:13:25] Speaker 5: the plugin we will also allow you to run these on demand so if you look at the categories here\n[2025-06-01 19:13:25] Speaker 5: compute throughput, temperature check, all these check, check, check,\n[2025-06-01 19:13:28] Speaker 5: model MFU based stuff.\n[2025-06-01 19:13:25] Speaker 5: All of those are readily available for you and we will very soon have a link that will exactly take\n[2025-06-01 19:13:25] Speaker 5: you to a JSON that is very much deeper on all the tests. This is basically the JSON that the health check.\n[2025-06-01 19:13:25] Speaker 5: script create like what's the bandwidth achieved the tflops achieved for each of the node which\n[2025-06-01 19:13:25] Speaker 5: GPU ran this for example right this is the GPU ID of an H100 we ran this is actually the JSON document\n[2025-06-01 19:13:25] Speaker 5: you'll have access to this as well as the logs piece uh but in a grafana it looks\n[2025-06-01 19:13:25] Speaker 5: Now, it's an easier way for you to digest all of this.\n[2025-06-01 19:13:27] Speaker 5: Let me put it up.\n[2025-06-01 19:13:25] Speaker 5: end of the day it's the same data but everything is a very detailed data that you may\n[2025-06-01 19:13:25] Speaker 5: be looking for um than just a summary like this okay both are available okay so we will add more\n[2025-06-01 19:13:25] Speaker 5: filters when it allows you to you know go by region and check the gpu types if you have mi300x\n[2025-06-01 19:13:25] Speaker 5: So Osaka does not have, maybe I think other machines in Chicago have MI300X.\n[2025-06-01 19:13:25] Speaker 5: see here yes you can see my 300x instance um so yeah these are all of both uh my 300x\n[2025-06-01 19:13:25] Speaker 5: as well as GPU from NVidia are fully monitored.\n[2025-06-01 19:13:29] Speaker 5: And we have health checks running for both.\n[2025-06-01 19:13:25] Speaker 5: Okay, so all of this is the data that you may be interested in.\n[2025-06-01 19:13:25] Speaker 5: that allows you to kind of baseline and benchmark all of this. Okay. So all of these metrics are\n[2025-06-01 19:13:25] Speaker 5: natively available in Prometheus and if I have to show you so we push with OCI\n[2025-06-01 19:13:25] Speaker 5: lens labels to this and this will allow you to extend it any further you like.\n[2025-06-01 19:13:25] Speaker 5: custom boards if you like, or you want to merge left join, right join some datasets here to get to more.\n[2025-06-01 19:13:25] Speaker 5: details everything is fully available that's just native krafanov right this is the lcl lens\n[2025-06-01 19:13:25] Speaker 5: health check stuff too. There is quite a bit of\n[2025-06-01 19:13:31] Speaker 5: health. Yeah, this is the health summary.\n[2025-06-01 19:13:25] Speaker 5: So all of these metrics, the only thing that we are adding,\n[2025-06-01 19:13:27] Speaker 5: this comes out as OCI lens.\n[2025-06-01 19:13:25] Speaker 5: anything that comes directly from the vendor,\n[2025-06-01 19:13:26] Speaker 5: like AMD or NVIDIA come as is, right?\n[2025-06-01 19:13:29] Speaker 5: DCGM append it.\n[2025-06-01 19:13:25] Speaker 5: So one additional thing we also did is if you know, let me go back here.\n[2025-06-01 19:13:25] Speaker 5: So this is the overall health board.\n[2025-06-01 19:13:28] Speaker 5: And there's another board that we bring is this is.\n[2025-06-01 19:13:25] Speaker 5: per host data right this is the actual gpu rdma metrics uh you know you know node health and all\n[2025-06-01 19:13:25] Speaker 5: that. Additional things that we are trying to add is if you come here and look at this table.\n[2025-06-01 19:13:25] Speaker 5: We will improve the UI a little bit,\n[2025-06-01 19:13:27] Speaker 5: but there is something called host metadata survey.\n[2025-06-01 19:13:25] Speaker 5: It's basically a local service endpoint that we hit\n[2025-06-01 19:13:28] Speaker 5: and we fetch the serial number because if the-\n[2025-06-01 19:13:25] Speaker 5: host is underperforming and you have to turn back it in for repair.\n[2025-06-01 19:13:29] Speaker 5: You know, some data that we have.\n[2025-06-01 19:13:25] Speaker 5: going to publish here is going to be super helpful.\n[2025-06-01 19:13:27] Speaker 5: And we are looking at how to put an agent.\n[2025-06-01 19:13:25] Speaker 5: AI on top of this, right? Let's\n[2025-06-01 19:13:26] Speaker 5: shortcut that, right? So we\n[2025-06-01 19:13:28] Speaker 5: will instead of throwing more\n[2025-06-01 19:13:25] Speaker 5: more boards, we will kind of curate an experience where if you see a underperforming node or a bad,\n[2025-06-01 19:13:25] Speaker 5: node. We may automate some of that to see if we could automatically raise a ticket or turn the\n[2025-06-01 19:13:25] Speaker 5: machine in or invoke folks in the support team to help you guys out.\n[2025-06-01 19:13:30] Speaker 5: So that's the.\n[2025-06-01 19:13:25] Speaker 5: future roadmap. So yeah, everything here, we're going to add more stuff like what's the\n[2025-06-01 19:13:25] Speaker 5: the huda driver you're running what's the kernel versions you're running um what's the OS\n[2025-06-01 19:13:25] Speaker 5: attached to, what's the Rockham driver version you're running, all of those data will be fully\n[2025-06-01 19:13:25] Speaker 5: available everything related to metadata will be published here and you can continue to\n[2025-06-01 19:13:25] Speaker 5: use that instead of you SSHing into the machine,\n[2025-06-01 19:13:28] Speaker 5: running some commands and all of that.\n[2025-06-01 19:13:25] Speaker 5: So, readily available.\n[2025-06-01 19:13:27] Speaker 5: Everything else you see here is something you may have been using already.\n[2025-06-01 19:13:25] Speaker 5: which is power, usage, temperature, utilization,\n[2025-06-01 19:13:28] Speaker 5: all that stuff.\n[2025-06-01 19:13:30] Speaker 5: Okay.\n[2025-06-01 19:13:31] Speaker 5: So in an actual, this-\n[2025-06-01 19:13:25] Speaker 5: this is this is what it is right so at least our first iteration of um can we get a monitor\n[2025-06-01 19:13:25] Speaker 5: going which is native and health checks going which is what lci published health checks and\n[2025-06-01 19:13:25] Speaker 5: just always vendor specified. So I'm gonna stop here and see if you folks have questions.\n[2025-06-01 19:13:25] Speaker 5: and also talk about some feedback if you have for us.\n[2025-06-01 19:13:32] Speaker 1: Thanks for the demo.\n[2025-06-01 19:13:33] Speaker 1: I have a few...\n[2025-06-01 19:13:25] Speaker 1: questions um so i think you mentioned in the first slide one of the things being like um you know\n[2025-06-01 19:13:25] Speaker 1: Kubernetes native, cloud native,\n[2025-06-01 19:13:26] Speaker 1: which was one of the things we discussed previously\n[2025-06-01 19:13:28] Speaker 1: as being one of the...\n[2025-06-01 19:13:25] Speaker 1: key things really important for us um what other levels of integrations with oke are you planning\n[2025-06-01 19:13:25] Speaker 1: at all, if any.\n[2025-06-01 19:13:26] Speaker 1: Things that top of mind would be super helpful\n[2025-06-01 19:13:28] Speaker 1: for us would be being able to\n[2025-06-01 19:13:25] Speaker 1: surface some of these unhealthy node conditions to OKE or to the actual Kubernetes object.\n[2025-06-01 19:13:25] Speaker 1: so that we can use that in our tooling.\n[2025-06-01 19:13:27] Speaker 1: And then, you know, when we're launching, submitting jobs.\n[2025-06-01 19:13:25] Speaker 1: being able to detect that a node is unhealthy.\n[2025-06-01 19:13:28] Speaker 1: The other thing I think is like the monitoring.\n[2025-06-01 19:13:25] Speaker 1: the rings that you mentioned, I don't think that would be super helpful for us because we're not\n[2025-06-01 19:13:25] Speaker 1: assigning nodes to people or teams.\n[2025-06-01 19:13:28] Speaker 1: Instead, we're extremely dynamic.\n[2025-06-01 19:13:31] Speaker 1: So we have...\n[2025-06-01 19:13:25] Speaker 1: you know, super cluster of thousands of GPUs.\n[2025-06-01 19:13:27] Speaker 1: And those nodes get used.\n[2025-06-01 19:13:30] Speaker 1: We use Q, which is a native.\n[2025-06-01 19:13:25] Speaker 1: Kubernetes project to schedule workloads.\n[2025-06-01 19:13:30] Speaker 1: So at any given time, we want to know, like, this\n[2025-06-01 19:13:25] Speaker 1: job is running with, you know, 128 GPUs, are any of the nodes unhealthy in this job? And so that job\n[2025-06-01 19:13:25] Speaker 1: might be using a different set of nodes than another job would be for the same team the next\n[2025-06-01 19:13:25] Speaker 1: day. So something like that would be helpful. Okay, wonderful. I think for the answer for the first\n[2025-06-01 19:13:25] Speaker 5: one is uh we are working with okay team i think okay team also has added some features lately where\n[2025-06-01 19:13:25] Speaker 5: they can detect an unhealthy gpu node and start tagging them as unallocatable uh for some some\n[2025-06-01 19:13:25] Speaker 5: the checks that they ran.\n[2025-06-01 19:13:27] Speaker 5: So we are actually working with them\n[2025-06-01 19:13:29] Speaker 5: to see if anything...\n[2025-06-01 19:13:25] Speaker 5: we find in our health check uh that uh that says that you know this node one of the gpus in the\n[2025-06-01 19:13:25] Speaker 5: node is continuous to underperform and communicate back on unschedulable.\n[2025-06-01 19:13:25] Speaker 5: we will have that integration point in the future for sure.\n[2025-06-01 19:13:29] Speaker 5: Right. So, and the metrics from.\n[2025-06-01 19:13:25] Speaker 5: OKE directly. So if there are part level, position volume level and lower\n[2025-06-01 19:13:25] Speaker 5: of good healthy prometheus metrics that come we can directly pipe all of those into this lens with\n[2025-06-01 19:13:25] Speaker 5: added set of things from our side to kind of consolidate and give you that one view that means\n[2025-06-01 19:13:25] Speaker 5: be needed. So that definitely is the plan, but we are looking into, okay, now a customer has to run.\n[2025-06-01 19:13:25] Speaker 5: a Prometheus instance in a Kubernetes cluster and that complication is what we're trying to do.\n[2025-06-01 19:13:25] Speaker 5: tackle the next feature set.\n[2025-06-01 19:13:29] Speaker 1: Okay, makes sense.\n[2025-06-01 19:13:30] Speaker 1: Yeah, just to reemphasize.\n[2025-06-01 19:13:25] Speaker 1: this is like probably the most important thing for us like really being able to\n[2025-06-01 19:13:25] Speaker 1: because we want to be able to do this automatically, right?\n[2025-06-01 19:13:28] Speaker 1: If a GPU breaks overnight, we don't want...\n[2025-06-01 19:13:25] Speaker 1: someone to have to, you know, go do something, go look at a Grafana dashboard we want.\n[2025-06-01 19:13:25] Speaker 1: our jobs to automatically react to these things.\n[2025-06-01 19:13:28] Speaker 5: Yeah. So I think that that brings another second.\n[2025-06-01 19:13:25] Speaker 5: question or even feedback you had for us is like the static way of creating monitoring ranks is\n[2025-06-01 19:13:25] Speaker 5: not ideal we fully hear you uh i think because of the dynamic if you're using q where you know\n[2025-06-01 19:13:25] Speaker 5: you get it booted out based on what team and priority and cohort and all of those stuff are.\n[2025-06-01 19:13:25] Speaker 5: We will integrate with OKE and the way we will look at is where the job is running or where\n[2025-06-01 19:13:25] Speaker 5: the deployment is running at a point of time and try to dynamically what we call add more tags to\n[2025-06-01 19:13:25] Speaker 5: metadata that's coming in to exactly relate to what experiment who ran it when when did it\n[2025-06-01 19:13:25] Speaker 5: complete timestamp it and try to pull those in.\n[2025-06-01 19:13:28] Speaker 5: So it's a thing that we are working.\n[2025-06-01 19:13:25] Speaker 5: towards, but we started with more non-Kubernetes-based experience, and then we would quick switch.\n[2025-06-01 19:13:25] Speaker 5: move into the dynamic workload where we pull in the nodes and even the GPUs, right?\n[2025-06-01 19:13:30] Speaker 5: Not full nodes.\n[2025-06-01 19:13:25] Speaker 5: be running every experiment so we will try to say four out of that no GPUs were running for this\n[2025-06-01 19:13:25] Speaker 5: experiment and that's what is aggregated into that board.\n[2025-06-01 19:13:28] Speaker 5: We will, that's a good point.\n[2025-06-01 19:13:25] Speaker 5: feedback and I think we will try to prioritize that.\n[2025-06-01 19:13:27] Speaker 5: Yeah, I think you're not very far from.\n[2025-06-01 19:13:25] Speaker 1: that honestly even without having to do like tagging of instances and trying to keep track of\n[2025-06-01 19:13:25] Speaker 1: what's running what. I think you could do some queries in your dashboard that just...\n[2025-06-01 19:13:25] Speaker 1: shows like your health metrics and then also use Kubernetes metrics and see like for\n[2025-06-01 19:13:25] Speaker 1: any given job or deployment, like you said, show all the nodes of that job and show if\n[2025-06-01 19:13:25] Speaker 1: of them are unhealthy so i think it's just a matter of like tying everything together\n[2025-06-01 19:13:25] Speaker 5: Yeah, I fully agree. Actually, we started like that, by the way, and I think Joleta and...\n[2025-06-01 19:13:25] Speaker 5: and most of my team knows that we started with a full Kubernetes-based experience, but we were nudged.\n[2025-06-01 19:13:25] Speaker 5: on like well i think there are a lot of people who want a full monitoring and this is where we\n[2025-06-01 19:13:25] Speaker 5: I think we have the both. We like to just pull it in like you said.\n[2025-06-01 19:13:25] Speaker 5: and start relating where, where, what is running\n[2025-06-01 19:13:28] Speaker 5: and start kind of creating that.\n[2025-06-01 19:13:25] Speaker 5: key value pair mapping here.\n[2025-06-01 19:13:25] Speaker 1: That's another question I'll have and then I'll pass it to like other.\n[2025-06-01 19:13:25] Speaker 1: Luis, Ace, if you have any questions, is you mentioned health checks. Can you talk?\n[2025-06-01 19:13:25] Speaker 1: a bit more about um how those would run like are you running anything that requires the workload\n[2025-06-01 19:13:25] Speaker 1: to be idle and if so is it or the gpu note to be idle and if so is it going to be doing\n[2025-06-01 19:13:25] Speaker 1: something like when nodes go idle to check the gpus or are these like running passively in the background\n[2025-06-01 19:13:25] Speaker 5: So I'll ask Soumya to chime in as well on she's an ML engineer worked on the script.\n[2025-06-01 19:13:25] Speaker 5: So we run this, we expect the GPUs to be idle and no workloads to be running.\n[2025-06-01 19:13:25] Speaker 5: this is where the PyTorch is loading into the tensor so it's loading into the accelerator.\n[2025-06-01 19:13:25] Speaker 5: running all these checks and coming back.\n[2025-06-01 19:13:27] Speaker 5: So we expect no workloads to be running when this.\n[2025-06-01 19:13:25] Speaker 5: this is running. We run it when you say you need to run it.\n[2025-06-01 19:13:28] Speaker 5: Right now we have not automated it.\n[2025-06-01 19:13:25] Speaker 5: And this is where we need feedback.\n[2025-06-01 19:13:26] Speaker 5: Like, do you want to run at midnight, 12 o'clock every day?\n[2025-06-01 19:13:25] Speaker 5: right you need that kind of no definitely not\n[2025-06-01 19:13:25] Speaker 1: Yeah, if I'm an ML engineer, I'm like, okay, I know when my pipeline is at a pause where I say call.\n[2025-06-01 19:13:25] Speaker 5: of my gpus are flushed out and idle i want to run the health checks for everything and make sure\n[2025-06-01 19:13:25] Speaker 5: of that is good before we go to the next phase, right? Is that an experience you would look for?\n[2025-06-01 19:13:25] Speaker 5: What we are thinking is we will give you a on-demand way for you to invoke health checkscripts.\n[2025-06-01 19:13:25] Speaker 5: through a REST API.\n[2025-06-01 19:13:26] Speaker 5: You have to just say\n[2025-06-01 19:13:28] Speaker 5: when you want to run it\n[2025-06-01 19:13:30] Speaker 5: and you on-demand run it.\n[2025-06-01 19:13:25] Speaker 5: Because we don't know when your GPUs are idle, then they're not.\n[2025-06-01 19:13:25] Speaker 1: Interesting. I was thinking like you might be able to figure that out like from a program.\n[2025-06-01 19:13:25] Speaker 1: programmatic standpoint, you might be able to get that data and whenever they are idle.\n[2025-06-01 19:13:25] Speaker 1: kick off like a workload that runs the Huff check.\n[2025-06-01 19:13:30] Speaker 1: So the intuition behind creating\n[2025-06-01 19:13:25] Speaker 3: this health check recipe is imagine a machine learning engineer or like you have a team that's\n[2025-06-01 19:13:25] Speaker 3: going to do a multi-node training or like multi-node fine tuning, right?\n[2025-06-01 19:13:29] Speaker 3: Before you go into doing...\n[2025-06-01 19:13:25] Speaker 3: a large-scale training operation or like any kind of like workload that's going to take too much\n[2025-06-01 19:13:25] Speaker 3: demand of the GPU itself.\n[2025-06-01 19:13:27] Speaker 3: You'd want to run this health check before that to understand that\n[2025-06-01 19:13:25] Speaker 3: health of your infrastructure right for example the way this health check is designed is it's based\n[2025-06-01 19:13:25] Speaker 3: on just 10 0 matrix multiplication right so depending upon the matrix size you probably be\n[2025-06-01 19:13:25] Speaker 3: loading like 818 like imagine like a matrix size of like 8192 by 818\n[2025-06-01 19:13:25] Speaker 3: too right you're going to be loading all these matrix into the gpu memory and we are going to\n[2025-06-01 19:13:25] Speaker 3: pressurize and see how much your machine is able to take the computation throughput or like throat\n[2025-06-01 19:13:25] Speaker 3: the power and things like that. So ideally you would want to do it when your machine is idle and to\n[2025-06-01 19:13:25] Speaker 3: address your point yeah we could actually schedule and understand when the jobs are not running\n[2025-06-01 19:13:25] Speaker 3: and we could just run the health check at that point.\n[2025-06-01 19:13:27] Speaker 3: And we can detect when the machines are...\n[2025-06-01 19:13:25] Speaker 3: Yeah, I think it'd be interesting to have the option to schedule it on demand, like as a...\n[2025-06-01 19:13:25] Speaker 1: we hook like to the jobs like you said um but i don't i need to think more about this\n[2025-06-01 19:13:25] Speaker 1: But I think, you know, my intuition is why not both, you know, like having a periodic check.\n[2025-06-01 19:13:25] Speaker 1: that best effort runs when the node is sitting there doing nothing.\n[2025-06-01 19:13:29] Speaker 1: So that if a node does go unhealthy,\n[2025-06-01 19:13:25] Speaker 1: we can find out about it early and not wait for a job to get scheduled there to find out.\n[2025-06-01 19:13:25] Speaker 5: Yeah, no, we'll take it as a good feedback.\n[2025-06-01 19:13:28] Speaker 5: We have still, because we have to think.\n[2025-06-01 19:13:25] Speaker 5: through a little bit on scheduling because it takes roughly five minutes for this head check\n[2025-06-01 19:13:25] Speaker 5: to finish and in mix of this if your queue ends up scheduling another job uh they'll they'll\n[2025-06-01 19:13:25] Speaker 5: it can't find an ideal GPU. So they go on pending. So we have to just think through this.\n[2025-06-01 19:13:25] Speaker 5: Yeah, no, this would definitely, yes, this would definitely have to be an...\n[2025-06-01 19:13:25] Speaker 1: interruptible workload so that our workloads can always schedule the priority.\n[2025-06-01 19:13:25] Speaker 5: Exactly right you cannot boot this workload because this is running at the system\n[2025-06-01 19:13:25] Speaker 5: level, right? And Kubernetes layers are at a much higher layer too.\n[2025-06-01 19:13:25] Speaker 5: and we need to think of this a little bit but i think this is really good feedback um thank you\n[2025-06-01 19:13:25] Speaker 1: Yeah, no, thank you.\n[2025-06-01 19:13:26] Speaker 1: Louise Ace, you have anything?\n[2025-06-01 19:13:25] Speaker 4: Mostly just echoing your thoughts. I mean, when we talk about node lifecycle,\n[2025-06-01 19:13:25] Speaker 4: It's very much like an ongoing thing.\n[2025-06-01 19:13:26] Speaker 4: It's not sort of a one off thing.\n[2025-06-01 19:13:27] Speaker 4: So just, yeah.\n[2025-06-01 19:13:25] Speaker 4: like having both elements and thinking about how nodes like proceed through.\n[2025-06-01 19:13:25] Speaker 4: I don't want to say this process exactly, but like, I don't know, mostly just echoing Cecile's\n[2025-06-01 19:13:25] Speaker 4: thoughts. Okay. Yeah. Thank you. So what, what we are trying to also avoid is before you shut this\n[2025-06-01 19:13:25] Speaker 5: machine and turn it back into OCI to repair. We want to see what is the issue, right?\n[2025-06-01 19:13:25] Speaker 5: deeper into what where is the concern is it a single gpu always coming back with a lower\n[2025-06-01 19:13:25] Speaker 5: performance compared to the rest seven of them in the same node or is it consistent uh no\n[2025-06-01 19:13:25] Speaker 5: RDMA nick flapping issues, errors that show up.\n[2025-06-01 19:13:28] Speaker 5: And this is a start.\n[2025-06-01 19:13:30] Speaker 5: And where we want to go.\n[2025-06-01 19:13:25] Speaker 5: is if we start seeing a pattern of things which are very consistent with a lot of other customers\n[2025-06-01 19:13:25] Speaker 5: and a lot of type of GPUs,\n[2025-06-01 19:13:26] Speaker 5: we will come back with recommendations\n[2025-06-01 19:13:28] Speaker 5: through an agentic AI type of app.\n[2025-06-01 19:13:25] Speaker 5: flow where probably just a reboot may fix the things or it could be specific to a driver.\n[2025-06-01 19:13:25] Speaker 5: the GPU driver you have, which has seen this incompatibility with the Mellanox drivers we have.\n[2025-06-01 19:13:25] Speaker 5: example. So we are trying to learn from using the data as well as all the issues customers.\n[2025-06-01 19:13:25] Speaker 5: give us to start recommending, right?\n[2025-06-01 19:13:27] Speaker 5: So this is just a start for us to start collecting,\n[2025-06-01 19:13:29] Speaker 5: but next approach for us is\n[2025-06-01 19:13:25] Speaker 5: remove the noise and tell if there is really a issue with the host or if this is a transient issue.\n[2025-06-01 19:13:25] Speaker 5: or not an issue with something related to an experiment that has been set up.\n[2025-06-01 19:13:25] Speaker 5: workload is being scheduled on this or the topology that it's been deployed with.\n[2025-06-01 19:13:29] Speaker 5: Any of those questions?\n[2025-06-01 19:13:25] Speaker 5: Right, so that's where we want to get to.\n[2025-06-01 19:13:25] Speaker 5: Awesome. So here's the log as well.\n[2025-06-01 19:13:28] Speaker 5: This is this we'll build up more and more.\n[2025-06-01 19:13:25] Speaker 5: stuff and it's all accessible either through portal or an api where you don't have to assess\n[2025-06-01 19:13:25] Speaker 5: an instance. Because the scripts are going to be standardized that what you see against\n[2025-06-01 19:13:25] Speaker 5: what OCI support sees everything will be consistent and maybe in the future once we have support team\n[2025-06-01 19:13:25] Speaker 5: running full diagnosis they know where to narrow down the issue to like exact GPU or the NICs or\n[2025-06-01 19:13:25] Speaker 5: anything instead of running this full you know six hours uh diagnosis on the host right\n[2025-06-01 19:13:25] Speaker 5: So we're just trying to narrow down that time it takes to fix these machines too.\n[2025-06-01 19:13:30] Speaker 5: So that will help.\n[2025-06-01 19:13:25] Speaker 1: When you say consistent, is the idea that you give us a set of scripts and we run these?\n[2025-06-01 19:13:25] Speaker 1: or they see the results of our health checks.\n[2025-06-01 19:13:25] Speaker 1: So right now with the way it is integrated, the OCI support does not see the results, but you could just take...\n[2025-06-01 19:13:25] Speaker 5: these results copy paste in your support ticket if you need to OCI support will have access\n[2025-06-01 19:13:25] Speaker 5: the same health check tools and scripts that you are running.\n[2025-06-01 19:13:29] Speaker 5: So it's a consistent tool.\n[2025-06-01 19:13:25] Speaker 5: that you both are running,\n[2025-06-01 19:13:26] Speaker 5: where what you have seen as the results,\n[2025-06-01 19:13:29] Speaker 5: for example, the score,\n[2025-06-01 19:13:25] Speaker 5: So here's the flops, for example.\n[2025-06-01 19:13:28] Speaker 5: This is the duration, right?\n[2025-06-01 19:13:30] Speaker 5: What you are seeing...\n[2025-06-01 19:13:25] Speaker 5: when OCI support is trying to run this on their own.\n[2025-06-01 19:13:28] Speaker 5: There is a lot of consistency.\n[2025-06-01 19:13:25] Speaker 5: Right. And if you see this GPU consistently coming back with like, okay, it takes 31 seconds.\n[2025-06-01 19:13:25] Speaker 5: It's easy to narrow down saying that GQ7 is something.\n[2025-06-01 19:13:25] Speaker 5: that we need to request.\n[2025-06-01 19:13:25] Speaker 1: I see. Yeah, I think it would be even better if we can get to a stage where they...\n[2025-06-01 19:13:25] Speaker 1: like have access to historical results and they can just see things that are\n[2025-06-01 19:13:28] Speaker 1: ZeeBrand.\n[2025-06-01 19:13:25] Speaker 1: Yeah.\n[2025-06-01 19:13:25] Speaker 1: instead of having to reproduce and copy pasting things.\n[2025-06-01 19:13:25] Speaker 1: i fully agree i think that's our goal but we are not a oci service yet\n[2025-06-01 19:13:25] Speaker 5: right and uh because it's all running the customer's tenancy uh there's obviously\n[2025-06-01 19:13:25] Speaker 5: little bit of things about what we can collect, what we cannot. And we had to go through those.\n[2025-06-01 19:13:25] Speaker 5: product approval phases.\n[2025-06-01 19:13:28] Speaker 5: And then we will probably\n[2025-06-01 19:13:29] Speaker 5: support and have access to this.\n[2025-06-01 19:13:25] Speaker 1: Okay, makes sense. One other question for Prometheus. You mentioned at some point in the\n[2025-06-01 19:13:25] Speaker 1: this slide something about setting up a CPU cluster or gate cluster to run Prometheus.\n[2025-06-01 19:13:25] Speaker 1: can we reuse our existing primukes instead?\n[2025-06-01 19:13:25] Speaker 5: Yes, yes, absolutely. You can use your existing. You need to just enable push gateway and add.\n[2025-06-01 19:13:25] Speaker 5: push gateway configurations because that's how all of the scripts push their results and metrics.\n[2025-06-01 19:13:25] Speaker 5: Okay, can you give a bit more detail about how this works?\n[2025-06-01 19:13:25] Speaker 1: scripts push metrics or how does that work\n[2025-06-01 19:13:25] Speaker 5: Yeah, Hrithika, can you elaborate on this?\n[2025-06-01 19:13:25] Speaker 2: Hello? Can you hear me?\n[2025-06-01 19:13:25] Speaker 5: Is VTK wrong?\n[2025-06-01 19:13:25] Speaker 5: Yeah.\n[2025-06-01 19:13:25] Speaker 2: All right. Could you give that question once again?\n[2025-06-01 19:13:25] Speaker 1: It was just having a bit more detail about how the metrics get emitted.\n[2025-06-01 19:13:25] Speaker 1: Because I understand there are scripts and then I'm just trying to figure out like how we could.\n[2025-06-01 19:13:25] Speaker 1: scrape our own metrics.\n[2025-06-01 19:13:25] Speaker 1: Oh yeah, so we basically build the node exporter, DCGM, AMD exporter, all of that depending on the GPU.\n[2025-06-01 19:13:25] Speaker 2: it is and bring those up and there are also some metrics which are OCI specific which are\n[2025-06-01 19:13:25] Speaker 2: return in a Go plugin and that plugin\n[2025-06-01 19:13:29] Speaker 2: fits metrics to the push gateway at a regular interval.\n[2025-06-01 19:13:25] Speaker 5: Yeah, all of the scripts here are...\n[2025-06-01 19:13:27] Speaker 5: Does that make sense?\n[2025-06-01 19:13:25] Speaker 5: push gateway if you see it here and\n[2025-06-01 19:13:25] Speaker 5: And these are scraped by Prometheus\n[2025-06-01 19:13:27] Speaker 5: based on Prometheus script config.\n[2025-06-01 19:13:29] Speaker 5: And-\n[2025-06-01 19:13:25] Speaker 5: Push gateway is part of a service that is default in Prometheus server install.\n[2025-06-01 19:13:30] Speaker 5: And it's the same.\n[2025-06-01 19:13:25] Speaker 5: mechanism.\n[2025-06-01 19:13:27] Speaker 5: Gotcha.\n[2025-06-01 19:13:28] Speaker 1: Okay.\n[2025-06-01 19:13:28] Speaker 1: I'll look into this a bit more.\n[2025-06-01 19:13:29] Speaker 1: I haven't used push gateway before.\n[2025-06-01 19:13:25] Speaker 1: So that's probably where my gap comes from.\n[2025-06-01 19:13:27] Speaker 1: Okay.\n[2025-06-01 19:13:27] Speaker 5: Yeah, I think it's part of the setup.\n[2025-06-01 19:13:25] Speaker 5: And if you go, if you run Prometheus through operator,\n[2025-06-01 19:13:28] Speaker 5: Push Gateway is usually installed as a service.\n[2025-06-01 19:13:25] Speaker 5: It should have its own service endpoint,\n[2025-06-01 19:13:28] Speaker 5: and you have to just enable a few things.\n[2025-06-01 19:13:25] Speaker 5: and you're good to go. Yeah. So, this is for instead of you going and reaching out.\n[2025-06-01 19:13:25] Speaker 5: going and reaching out and pulling the metrics out which is where you need firewall exception\n[2025-06-01 19:13:25] Speaker 5: and opening the ports and all of that.\n[2025-06-01 19:13:27] Speaker 5: Here, any metrics you are generating, including DCGM,\n[2025-06-01 19:13:25] Speaker 5: all of those are pool metrics, right?\n[2025-06-01 19:13:27] Speaker 5: We push it directly to the push page.\n[2025-06-01 19:13:25] Speaker 5: and your Prometheus is scraping push gateway basically.\n[2025-06-01 19:13:29] Speaker 5: It's like an intermediate data store.\n[2025-06-01 19:13:25] Speaker 5: All right. Any further questions? And we are also eager if you have any feedback.\n[2025-06-01 19:13:25] Speaker 5: can think about we are thinking in next roughly two weeks you can you can have access to all of\n[2025-06-01 19:13:25] Speaker 5: the health check scripts.\n[2025-06-01 19:13:27] Speaker 5: We'll get access to your repo\n[2025-06-01 19:13:29] Speaker 5: once you share your GitHub IDs.\n[2025-06-01 19:13:25] Speaker 5: can poke around and really we are here to listen and and build something that that makes uh\n[2025-06-01 19:13:25] Speaker 5: life easy right so we are here to listen and you know continue to iterate as fast as we\n[2025-06-01 19:13:25] Speaker 5: can to give you what you're looking for.\n[2025-06-01 19:13:27] Speaker 5: So.\n[2025-06-01 19:13:28] Speaker 1: Thanks, Samar.\n[2025-06-01 19:13:29] Speaker 1: I think overall this is, you know.\n[2025-06-01 19:13:25] Speaker 1: something that we've been asking for. So really, really happy it's, it's getting there.\n[2025-06-01 19:13:25] Speaker 1: and you all are focusing your efforts there.\n[2025-06-01 19:13:26] Speaker 1: It's definitely heading the right direction.\n[2025-06-01 19:13:25] Speaker 1: I think looking at what we have today that we built ourselves a best over the past year,\n[2025-06-01 19:13:29] Speaker 1: it's definitely...\n[2025-06-01 19:13:25] Speaker 1: not there yet. I think what we have right now is a bit more advanced just because we've built\n[2025-06-01 19:13:25] Speaker 1: our own set of scripts and like we've iterated on them and we have all that automation.\n[2025-06-01 19:13:25] Speaker 1: and integration with Kubernetes already.\n[2025-06-01 19:13:27] Speaker 1: But I like where this is going and yeah, excited too.\n[2025-06-01 19:13:25] Speaker 1: work with you all too.\n[2025-06-01 19:13:26] Speaker 1: It's great.\n[2025-06-01 19:13:27] Speaker 5: Okay.\n[2025-06-01 19:13:28] Speaker 5: Yeah.\n[2025-06-01 19:13:28] Speaker 5: We'll try to,\n[2025-06-01 19:13:30] Speaker 5: right now,\n[2025-06-01 19:13:31] Speaker 5: we are not overly\n[2025-06-01 19:13:25] Speaker 5: Kubernetes heavy features and if we will probably in the next iteration or a milestone\n[2025-06-01 19:13:25] Speaker 5: add all of those capabilities to bring Kubernetes metrics and that experience together.\n[2025-06-01 19:13:25] Speaker 5: And hopefully, Sisal, I'll post that.\n[2025-06-01 19:13:27] Speaker 5: You would be open to trying it out and giving us the feedback.\n[2025-06-01 19:13:25] Speaker 5: and iterating like that.\n[2025-06-01 19:13:29] Speaker 1: Sounds good.\n[2025-06-01 19:13:32] Speaker 5: Thanks for making the time to give us a demo.\n[2025-06-01 19:13:25] Speaker 1: Appreciate it.\n[2025-06-01 19:13:25] Speaker 5: Thanks for spending your time with us as well.\n[2025-06-01 19:13:28] Speaker 5: So anyone else, any questions?\n[2025-06-01 19:13:25] Speaker 1: Thank you.\n[2025-06-01 19:13:25] Speaker 1: Thank you.\n[2025-06-01 19:13:25] Speaker 1: Thank you.\n[2025-06-01 19:13:25] Speaker 1: Thank you.",
  "summary": "Key Points:\n\n* The OCI Lens initiative is currently in the incubation phase and is not yet an MVP or closer to it.\n* The team is focused on continuous GPU and cluster-level monitoring of both NVIDIA and AMD GPUs.\n* The solution includes active health checks and active monitoring, which is a huge investment.\n* The team has built team-level tracking, which allows multiple teams to monitor their own subset of systems.\n* The solution also includes cost tracking, which allows users to see how much computer resources they have used.\n\nAction Items:\n\n* The team will show a demo of the OCI Lens initiative, which allows users to monitor either single, bare metal, virtual machine instances, or a full OKE cluster or an HPC cluster.\n* The team is working towards automatically fetching the nodes that are running an experiment based on Kubernetes scheduling.\n* The team will demonstrate the difference between performance monitoring and health checks, which goes very close to the layers that an ML engineer would operate under.\n\n---\n\nKey points:\n\n* PyTorch and JAX are being considered for performance testing.\n* The approach is to push metrics and health check data to Prometheus and the central control plane.\n* The origination of all metrics is within the network.\n* There are plenty of metrics, including NVIDIA DCGM exporter, AMD SMI metrics, and RDMA metrics.\n* Health checks include traditional disk IO usage and are adjusted based on performance seen.\n* The architecture is evolving and will be deployed as a dedicated OKE cluster with CPU nodes.\n* The footprint includes Prometheus, Grafana, open source, and control plane API.\n* The demo will be shown, and questions can be asked after.\n\nDecisions:\n\n* PyTorch and JAX will be considered for performance testing.\n* The approach is to push metrics and health check data to Prometheus and the central control plane.\n\nAction items:\n\n* None specified in the transcript.\n\n---\n\nKey Points:\n\n* The meeting discussed a plug-in model for monitoring OCI lengths.\n* To start monitoring, an existing instance or a new instance being provisioned must include a script.\n* The architecture is simple and straightforward, with the monitoring running directly on the bare metal host.\n* The monitoring can be scanned for Kubernetes clusters, RDMA cluster networks, or compute clusters.\n* The experience is that when you check a Kubernetes cluster, all GPU nodes under it are automatically scanned and added to the monitoring.\n* The meeting showed a portal for accessing the monitoring through REST API endpoints.\n* The monitoring allows for the creation of a monitoring ring, which can be used to bundle all the things.\n* Every monitoring ring comes with a dedicated Grafana board.\n* The health summary of all compute nodes that are part of the monitoring was demonstrated.\n* The health checks include performance-related checks that are done on the host when the plugin is activated.\n* The health checks can be run on demand, and a link will soon be provided to a JSON that is deeper on all the tests.\n\nDecisions:\n\n* The monitoring will be started by including a script in an existing instance or a new instance being provisioned.\n* The monitoring will run directly on the bare metal host.\n* The monitoring can be scanned for Kubernetes clusters, RDMA cluster networks, or compute clusters.\n* The monitoring allows for the creation of a monitoring ring, which can be used to bundle all the things.\n\nAction Items:\n\n* Provide a link to a JSON that is deeper on all the tests.\n\n---\n\nSummary of Meeting:\n\n* The speaker presented a tool that provides detailed data on GPU usage, health, and performance.\n* The tool is natively available in Prometheus and can be extended with custom labels.\n* The speaker added that they are working on improving the UI and automating some tasks to help users identify and resolve issues more efficiently.\n* The speaker mentioned that they are planning to add more data related to metadata, such as host metadata survey, to provide a more comprehensive view of the system.\n* The speaker also mentioned that they are planning to add more boards to the tool to provide more information about the system.\n* The speaker mentioned that they are planning to add more features to the tool, such as automating some tasks and improving the UI.\n* The speaker mentioned that they are planning to add more data related to metadata, such as host metadata survey, to provide a more comprehensive view of the system.\n* The speaker mentioned that they are planning to add more boards to the tool to provide more information about the system.\n* The speaker mentioned that they are planning to add more features to the tool, such as automating some tasks and improving the UI.\n* The speaker mentioned that they are planning to add more data related to metadata, such as host metadata survey, to provide a more comprehensive view of the system.\n* The speaker mentioned that they are planning to add more boards to the tool to provide more information about the system.\n* The speaker mentioned that they are planning to add more features to the tool, such as automating some tasks and improving the UI.\n* The speaker mentioned that they are planning to add more data related to metadata, such as host metadata survey, to provide a more comprehensive view of the system.\n* The speaker mentioned that they are planning to add more boards to the tool to provide more information about the system.\n* The speaker mentioned that they are planning to add more features to the tool, such as automating some tasks and improving the UI.\n* The speaker mentioned that they are planning to add more data related to metadata, such as host metadata survey, to provide a more comprehensive view of the system.\n* The speaker mentioned that they are planning to add more boards to the tool to provide more information about the system.\n* The speaker mentioned that they are planning to add more features to the tool, such as automating some tasks and improving the UI.\n* The speaker mentioned that they are planning to add more data\n\n---\n\nKey points:\n\n* The team is working on a solution to automatically detect and react to unhealthy GPUs in a Kubernetes cluster.\n* The solution will involve integrating with the Open Kubernetes Engine (OKE) and dynamically adding tags to metadata.\n* The team is also working on improving the static way of creating monitoring ranks.\n* The team is looking into using Prometheus to monitor the health of GPUs in a Kubernetes cluster.\n\nDecisions:\n\n* The team will integrate with OKE to dynamically add tags to metadata.\n* The team will prioritize the development of a solution to automatically detect and react to unhealthy GPUs.\n\nAction items:\n\n* The team will continue working on integrating with OKE and dynamically adding tags to metadata.\n* The team will prioritize the development of a solution to automatically detect and react to unhealthy GPUs.\n\n---\n\nKey Points:\n\n* The team is currently not automating the running of health checks on GPUs.\n* Feedback is needed on when to run health checks, such as at midnight every day or on demand.\n* The team is considering giving an on-demand way for ML engineers to invoke health check scripts through a REST API.\n* The team is also considering creating a health check recipe that can be run before large-scale training operations to understand the health of the infrastructure.\n* The team is considering scheduling health checks on demand, as well as having a periodic check that runs when the node is idle.\n* The team is aware of the need for an interruptible workload so that workloads can always schedule their priority.\n* The team is trying to learn from data and customer issues to start recommending specific fixes for GPU driver incompatibilities.\n\nAction Items:\n\n* Determine the best way to invoke health check scripts on demand.\n* Create a health check recipe that can be run before large-scale training operations.\n* Schedule health checks on demand as well as having a periodic check that runs when the node is idle.\n* Develop an agentic AI-type app to learn from data and customer issues to start recommending specific fixes for GPU driver incompatibilities.\n\n---\n\nKey points:\n\n* The team is working on a new approach to diagnose issues with hosts or experiments scheduled on them.\n* The goal is to narrow down the time it takes to fix these machines.\n* The team is working on building a consistent tool that both OCI support and customers can use to diagnose issues.\n* The team is also working on improving the historical results and access to them for customers.\n* The team is exploring the possibility of reusing existing primukes instead of setting up a CPU cluster or gate cluster to run Prometheus.\n* The team is working on building node exporter, DCGM, AMD exporter, and other metrics exporters depending on the GPU.\n* The team is also working on integrating OCI-specific metrics into Prometheus.\n* The team is using push gateway to collect metrics from scripts and scrape them by Prometheus.\n\nDecisions:\n\n* The team will work on building a consistent tool that both OCI support and customers can use to diagnose issues.\n* The team will explore the possibility of reusing existing primukes instead of setting up a CPU cluster or gate cluster to run Prometheus.\n\nAction items:\n\n* The team will work on building node exporter, DCGM, AMD exporter, and other metrics exporters depending on the GPU.\n* The team will integrate OCI-specific metrics into Prometheus.\n* The team will use push gateway to collect metrics from scripts and scrape them by Prometheus.\n\n---\n\nKey points:\n\n* Push Gateway is a service that should have its own service endpoint.\n* Any metrics generated, including DCGM, are pool metrics that are pushed directly to the Push Gateway.\n* Prometheus is used to scrape the Push Gateway, acting as an intermediate data store.\n* Access to health check scripts will be provided in roughly two weeks once GitHub IDs are shared.\n* The team is focused on building something that makes life easy for the user.\n* The Push Gateway is not currently Kubernetes heavy, but Kubernetes capabilities may be added in the next iteration or milestone.\n* Sisal is open to trying out and giving feedback on the Push Gateway.\n\nDecisions:\n\n* The Push Gateway should be installed as a service with its own service endpoint.\n* Any metrics generated should be pushed directly to the Push Gateway.\n* Prometheus should be used to scrape the Push Gateway.\n* Access to health check scripts will be provided in roughly two weeks.\n\nAction items:\n\n* Enable a few things for the Push Gateway.\n* Share GitHub IDs to access health check scripts.\n* Iterate on the Push Gateway to add Kubernetes capabilities.\n* Try out and give feedback on the Push Gateway."
}