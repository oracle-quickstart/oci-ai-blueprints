# LoRA Fine-Tuning

#### Efficiently fine-tune large language models using Low-Rank Adaptation

This blueprint enables efficient model tuning using Low-Rank Adaptation (LoRA), a highly efficient method of LLM tuning. You can fine-tune a custom LLM or most open-source LLMs from Hugging Face. You can also use a custom dataset or any publicly available dataset from Hugging Face. Once the job is complete, results such as training metrics and logged in MLFlow for analysis. The fine-tuned model is then stored in an object storage bucket, ready for deployment.

## Pre-Filled Samples

| Feature Showcase                                                                               | Title                                                                                                                                        | Description                                                                                                                                                                         | Blueprint File                                                                                                       |
| ---------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------- |
| Fine-tune models from OCI Object Storage with checkpoint saving for efficient model management | Fine-Tune NousResearch/Meta-Llama-3.1-8B from Object Storage with Dataset from Hugging Face and Checkpoints saved in Object Storage (A10 VM) | Deploys Fine-Tune NousResearch/Meta-Llama-3.1-8B from Object Storage with Dataset from Hugging Face and Checkpoints saved in Object Storage (A10 VM) on VM.GPU.A10.2 with 2 GPU(s). | [bucket_checkpoint_bucket_model_open_dataset.backend.json](bucket_checkpoint_bucket_model_open_dataset.backend.json) |
| Fine-tune models from OCI Object Storage buckets for faster model loading and deployment       | Fine-Tune NousResearch/Meta-Llama-3.1-8B from Object Storage with Dataset from Hugging Face on A10 VM                                        | Deploys Fine-Tune NousResearch/Meta-Llama-3.1-8B from Object Storage with Dataset from Hugging Face on A10 VM on VM.GPU.A10.2 with 2 GPU(s).                                        | [bucket_model_open_dataset.backend.json](bucket_model_open_dataset.backend.json)                                     |
| Use pre-authenticated requests (PARs) for secure model loading from Object Storage             | Fine-Tune NousResearch/Meta-Llama-3.1-8B from Object Storage (PAR link) with Dataset from Hugging Face on A10 VM                             | Deploys Fine-Tune NousResearch/Meta-Llama-3.1-8B from Object Storage (PAR link) with Dataset from Hugging Face on A10 VM on VM.GPU.A10.2 with 2 GPU(s).                             | [bucket_par_open_dataset.backend.json](bucket_par_open_dataset.backend.json)                                         |
| Fine-tune gated HuggingFace models that require authentication tokens for access               | Fine-Tune meta-llama/Llama-3.2-1B-Instruct (Closed Model) from Hugging Face with Dataset from Hugging Face on A10 VM                         | Deploys Fine-Tune meta-llama/Llama-3.2-1B-Instruct (Closed Model) from Hugging Face with Dataset from Hugging Face on A10 VM on VM.GPU.A10.2 with 2 GPU(s).                         | [closed_model_open_dataset_hf.backend.json](closed_model_open_dataset_hf.backend.json)                               |
| Fine-tune open-source models directly from HuggingFace without authentication requirements     | Fine-Tune NousResearch/Meta-Llama-3.1-8B (Open Model) from Hugging Face with Dataset from Hugging Face on A10 VM                             | Deploys Fine-Tune NousResearch/Meta-Llama-3.1-8B (Open Model) from Hugging Face with Dataset from Hugging Face on A10 VM on VM.GPU.A10.2 with 2 GPU(s).                             | [open_model_open_dataset_hf.backend.json](open_model_open_dataset_hf.backend.json)                                   |
