benchmark_type: offline
offline_backend: sglang

model_path: /models/NousResearch/Meta-Llama-3.1-8B
tokenizer_path: /models/NousResearch/Meta-Llama-3.1-8B
trust_remote_code: true
conv_template: llama-2

input_len: 128
output_len: 128
num_prompts: 64
max_seq_len: 4096
max_batch_size: 8
dtype: auto
temperature: 0.7
top_p: 0.9

mlflow_uri: http://mlflow-benchmarking.corrino-oci.com:5000
experiment_name: "sglang-bench-doc-test-new"
run_name: "llama3-8b-sglang-test"


save_metrics_path: /benchmarking_output/benchmark_output_llama3_sglang.json

