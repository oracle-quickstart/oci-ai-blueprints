{
  "recipe_id": "cpu_inference",
  "recipe_mode": "service",
  "deployment_name": "cpu Inference mistral E4Flex",
  "recipe_image_uri": "iad.ocir.io/iduyx1qnmway/corrino-devops-repository:cpu_inference_service_v0.2",
  "recipe_node_shape": "VM.Standard.E4.Flex",
  "recipe_flex_shape_ocpu_count": 4,
  "recipe_flex_shape_memory_size_in_gbs": 64,
  "input_object_storage": [
    {
      "par": "https://objectstorage.us-ashburn-1.oraclecloud.com/p/3qaZRZ0A38V-k0A0eYPqx8XPB06V2WLTj6zOYXKYK97k--yNzEqcV3qsa0MdUcr3/n/iduyx1qnmway/b/ollama-models/o/",
      "mount_location": "/models",
      "volume_size_in_gbs": 20
    }
  ],
  "recipe_container_env": [
    {
      "key": "MODEL_NAME",
      "value": "mistral"
    },
    {
      "key": "PROMPT",
      "value": "What is the capital of Spain?"
    }
  ],
  "recipe_replica_count": 1,
  "recipe_container_port": "11434",
  "recipe_node_pool_size": 1,
  "recipe_node_boot_volume_size_in_gbs": 200,
  "recipe_container_command_args": [
    "--input_directory",
    "/models",
    "--model_name",
    "mistral"
  ],
  "recipe_ephemeral_storage_size": 100
}
