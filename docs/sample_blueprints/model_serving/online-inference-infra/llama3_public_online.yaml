benchmark_type: online
model: /models/NousResearch/Meta-Llama-3.1-8B-Instruct  # Updated model path
input_len: 64
output_len: 32
max_requests: 5
timeout: 300
num_concurrent: 1
results_dir: /online_output
llm_api: openai
llm_api_key: dummy-key
llm_api_base: https://llama8bobjvllm.129-80-16-111.nip.io/v1  # Updated to HTTPS
experiment_name: local-bench
run_name: llama3-test
mlflow_uri: http://mlflow-benchmarking.corrino-oci.com:5000
llmperf_path: /opt/llmperf-src
metadata: test=public-endpoint
save_metrics_path: /online_output/benchmark_output_llama3_online_public.json